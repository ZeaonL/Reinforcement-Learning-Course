{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN算法\n",
    "&emsp;&emsp;DQN是一种经典的基于值函数的深度强化学习算法，它将卷积神经网CNN与Q-Learnig算法相结合，利用CNN对图像的强大表征能力，将视频帧数据视为强化学习中的状态输入网络，然后由网络输出离散的动作值函数，Agent再根据动作值函数选择对应的动作。<br>\n",
    "&emsp;&emsp;DQN利用CNN输入原始图像数据，能够在不依赖于任意特定问题的情况下，采用相同的算法模型，在广泛的问题中获得较好的学习效果。正如在Atari游戏中，尽管各个游戏的动作具有不同迁移效果，且需要使用不同的策略来获得高分，但DQN可以使用相同的原始输入、网络框架和参数值，得到相应的动作值特征，并取得高分。<br>\n",
    "&emsp;&emsp;DQN算法常用于处理Atari游戏，但又不局限于此，它可以通过修改Q网络来处理不同的任务。例如：（1）如果输入为图像信息，则可以通过CNN构造Q网络；（2）如果输入为序列数据，则可以通过RNN构建Q网络；（3）如果要增加历史记忆能力，则可以通过结合CNN和长短期记忆模型（LSTM）来构建具有记忆能力的Q网络。<br>\n",
    "#### 模型架构\n",
    "&emsp;&emsp;深度Q网络模型架构的输入是距离当前时刻最近的4幅预处理后的图像。该输入信号经过3个卷积层和2个全连接层的非线性变换，变换成低维的、抽象的特征表达，并最终在输出层产生每个动作对应的Q值函数。具体模型架构如下：<br>\n",
    "&emsp;&emsp;（1）输入层：在Gym环境中，Atari游戏的视频帧大小210*160为像素，每个像素有128种色彩。为了使训练更高效，在保证图片重要特征的情况下，将每一游戏帧预处理为84*84像素的灰度图像，并将连续4帧的游戏图像组成4*84*84像素的张量，作为网络的输入。采用连续4帧画面的目的在于感知游戏环境的动态性。<br>\n",
    "&emsp;&emsp;（2）对输入层进行卷积操作。将经过预处理之后的最近4幅大小为84*84的图像作为输入，用32个卷积核对输入进行卷积操作，每个卷积核的大小为4*8*8，步长为4。<br>\n",
    "&emsp;&emsp;（3）对第一隐藏层的输出进行卷积操作。用64个卷积核对第一隐藏层的输出进行卷积操作，每个卷积核的大小为32*4*4，步长为2。这样经过卷积后，得到的特征图尺寸为9：，因此产生64幅大小为9*9的特征图作为第二隐藏层。最后通过ReLU激活函数对第二隐藏层进行线性变换。<br>\n",
    "&emsp;&emsp;（4）对第二隐藏层的输出进行卷积操作。用64个卷积核对第二隐藏层的输出进行卷积操作，每个卷积核的大小为64*3*3，步长为1。这样经过卷积后，得到的特征图尺寸为7：，因此产生64幅大小为7*7的特征图作为第三隐藏层。同理，对第三隐藏层的输出进行ReLU非线性变换，输出64幅大小为7*7的特征图。此时，第三隐藏层神经元的个数为：3136个。<br>\n",
    "&emsp;&emsp;（5）第三隐藏层与第四隐藏层的全连接操作。第四隐藏层神经元的个数为512个，这样第三隐藏层的的3136个神经元与第四隐藏层的512个神经元进行全连接操作，并使用ReLU函数进行非线性变换。<br>\n",
    "&emsp;&emsp;（6）第四隐藏层与输出层的全连接操作。由于输出层输出的是动作空间中所有动作的Q值，因此输出层神经元个数应为具体任务中动作空间的动作数目。以Atari 2600“打砖块”游戏为例，其输出为18个动作。这样第四层的512个神经元与输出层的18个神经元进行全连接操作，并使用ReLU函数进行线性变换。具体的模型架构如图11.1所示：<br>\n",
    "<center><img src=\"11-1.png\"></center><br>\n",
    "&emsp;&emsp;<center>图11.1 深度Q网络模型架构</center><br>\n",
    "\n",
    "#### 数据预处理\n",
    "&emsp;&emsp;以Gym中的Atari游戏为例，来阐述DQN算法的数据预处理过程。在Gym环境中，Atari游戏的原始图像尺寸为210*160个像素，每个像素有128种颜色。为了算法能更高效地执行，需要对原始图像进行预处理：（1）通过图像变换，使图像变为2种颜色的灰度图像；（2）裁剪掉原始图像中无关紧要的信息像素，使图像尺寸裁剪为个160*160像素；（3）图像进行下采样，使其尺寸变为84*84个像素。<br>\n",
    "#### 动态信息预处理\n",
    "&emsp;&emsp;在Gym环境中，模拟器可以以60帧/秒的速度生成实时游戏画面，每一时刻，Agent可以从环境模拟器中取出1帧静态信息，单纯地来处理每1帧静态图像很难表示出游戏的动态信息。因此DQN中选取当前时刻起的前N帧画面（N通常设置为：N=3,4,5），并将这些信息结合起来作为模型的输入，获得某一段时间的动态状态信息。通过这种方式，模型可以学习到更准确的动作值函数，在实验中N=4。<br>\n",
    "&emsp;&emsp;另外由于模拟器生成并显示画面的速度远远高于人类玩家操作的速度，同时游戏的邻近帧之间画面有极大的相似性，因此在状态帧的选择上，可以采取每次跳过一定的帧数，选取一个连续4帧的状态方式，这样既可以减少系统处理信息的数量，又可以使机器的处理速度与人类玩家保持一致。<br>\n",
    "\n",
    "#### 游戏得分预处理\n",
    "&emsp;&emsp;在Atari游戏中，由于游戏种类的不同，使得其得分系统差别很大，有的游戏得分可以上万，有的只能得到几分。为了使DQN模型适用于所有的游戏，并利用同样的模型拟合长期回报，DQN中将所有游戏每一轮得到的回报压缩到-1,+1之间。虽然对游戏来说有些不合理，但这样的处理确实更方便模型处理。<br>\n",
    "#### 游戏随机开始的预处理\n",
    "&emsp;&emsp;大多数游戏的开始场景都是固定的，如果每个游戏从开始时就按某种策略采样，Agent就会对很多相同的图像帧进行决策，这样不利于在学习过程中探索更多的画面。针对此问题，DQN中设定在游戏开始的很短的一段时间内（如最多30个状态），让Agent随机地执行动作，这样可以最大程度地获得不同的场景样本，确保采样的随机性。<br>\n",
    "#### 训练算法\n",
    "&emsp;&emsp;DQN之所以能够较好地将深度学习与强化学习相结合，是因为它引入了3个核心技术：（1）目标函数：使用卷积神经网络结合全连接作为动作值函数的逼近器，实现端到端的效果，输入为视频画面，输出为有限数量的动作值函数；（2）目标网络：设置目标网络来单独处理TD误差，使得目标值相对稳定；（3）经验回放机制：有效解决数据间的相关性和非静态性问题，使得网络输入的信息满足独立同分布的条件。<br>\n",
    "#### 目标函数\n",
    "&emsp;&emsp;在DQN中使用CNN作为动作值函数逼近器，通过使用CNN输出的近似动作值函数来逼近真实动作值函数，即：<br>\n",
    "<center>$Q(s,a,w)+q_{\\pi}(s,a)$</center><br>\n",
    "&emsp;&emsp;监督学习的一般方法是先确定损失函数L(w)，然后求其梯度，再使用SGD等方法更新参数w。DQN通过Q-learning算法构建网络的损失函数：<br>\n",
    "<center>$L(w)=E_{\\pi_{w}}[(r+{\\gamma}max_{a^{'},a^{'},w}-Q(s,a,w))^2]$</center><br>\n",
    "\n",
    "#### 目标网络\n",
    "&emsp;&emsp;由式（11.1）可以看出，DQN的预测Q值（当前Q值）和目标Q值使用了相同的网络模型和参数，当预测Q值增大时，目标Q值也会随之增大。由于数据本身存在的不稳定性，势必造成学习过程中产生波动，这在一定程度上增加了模型震荡和发散的危险。<br>\n",
    "&emsp;&emsp;为了解决该问题，DQN算法使用两个包含CNN的网络模型进行学习：（1）网络模型$Q(s,a,w)$代表预测Q网络，用于评估当前状态-动作对的价值；（2）网络模型$Q(s,a,w^{'})$代表目标Q网络，用于计算目标值。<br>\n",
    "&emsp;&emsp;DQN通过引入目标网络，使得一段时间内目标Q值保持不变，一定程度降低了预测Q值和目标Q值的相关性，降低了训练时损失值震荡和发散的可能性，充分保证了训练时间，提高了算法的稳定性。<br>\n",
    "\n",
    "#### 经验回放机制\n",
    "&emsp;&emsp;在深度学习中，要求输入的样本数据满足独立同分布。而在强化学习任务中，样本间往往是关联的、非静态的，如果直接使用关联的数据进行模型训练，会导致模型难收敛、损失值持续波动等问题。<br>\n",
    "&emsp;&emsp;基于此，DQN算法引入经验回放机制：将每个时刻Agent与环境交互得到的经验迁移样本存储到经验池中，在执行数步之后，从经验池D中随机取出批量（例如32个样本）大小的样本，作为离散数据输入神经网络，然后再采用小批量随机半梯度下降法（MBSGD）更新网络参数w。<br>\n",
    "&emsp;&emsp;我们将状态之间产生的信号或称为经验迁移样本。其中，T为布尔值类型，表示新的状态是否为终止状态。经验回放机制采用随机采样的方式，既提高了数据的利用率，又去除了数据间的关联性、非静态分布等问题，使得网络模型更加稳定和高效。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, random, pickle, os.path, math, glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import pdb\n",
    "import cv2\n",
    "\n",
    "from atari_wrappers import make_atari, wrap_deepmind,LazyFrames\n",
    "from IPython.display import clear_output\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(210, 160, 3)\n",
      "(84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and wrap the environment\n",
    "\n",
    "env = make_atari('BreakoutNoFrameskip-v4') # only use in no frameskip environment\n",
    "# env = make_atari('PongNoFrameskip-v4')\n",
    "\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True )\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)\n",
    "state_dim = env.observation_space.shape\n",
    "# env.render()\n",
    "test = env.reset()\n",
    "\n",
    "for i in range(100):\n",
    "    test = env.step(env.action_space.sample())[0]\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(env.render(\"rgb_array\").shape)\n",
    "plt.subplot(132)\n",
    "plt.imshow(test._force()[...,0],cmap = plt.cm.gray) \n",
    "print(test._force()[...,0].shape)\n",
    "plt.show()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_size =1+ (input_size+2*padding-kernel_size)/stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels=4, num_actions=5):\n",
    "        \"\"\"\n",
    "        Initialize a deep Q-learning network as described in\n",
    "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "        Arguments:\n",
    "            in_channels: number of channel of input.\n",
    "                i.e The number of most recent frames stacked together as describe in the paper\n",
    "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4) #(84 + 2*0-8)/4+1=20 \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc4(x.view(x.size(0), -1))) #输出的维度是为[x.size(0),1]\n",
    "        return self.fc5(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./image/图CNN.png\" height=\"500\" width=\"500\" ></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory_Buffer(object):\n",
    "    def __init__(self, memory_size=1000):\n",
    "        self.buffer = []\n",
    "        self.memory_size = memory_size\n",
    "        self.next_idx = 0\n",
    "        \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        data = (state, action, reward, next_state, done)\n",
    "        if len(self.buffer) <= self.memory_size: # buffer not full\n",
    "            self.buffer.append(data)\n",
    "        else: # buffer is full\n",
    "            self.buffer[self.next_idx] = data\n",
    "        self.next_idx = (self.next_idx + 1) % self.memory_size #先进先出\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randint(0, self.size() - 1)\n",
    "            data = self.buffer[idx]\n",
    "            state, action, reward, next_state, done= data\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "            \n",
    "            \n",
    "        return np.concatenate(states), actions, rewards, np.concatenate(next_states), dones\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(\\theta) = E_{\\pi_{\\theta}}[{(r+\\gamma{max_{a^{'}}}Q(s^{'},a^{'},\\theta^{'})-Q(s,a,\\theta))}^2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent: \n",
    "    def __init__(self, in_channels = 1, action_space = [], USE_CUDA = False, memory_size = 10000, epsilon  = 1, lr = 1e-4):\n",
    "        self.epsilon = epsilon\n",
    "        self.action_space = action_space\n",
    "        self.memory_buffer = Memory_Buffer(memory_size)\n",
    "        self.DQN = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
    "        self.DQN_target = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
    "        self.DQN_target.load_state_dict(self.DQN.state_dict())\n",
    "\n",
    "\n",
    "        self.USE_CUDA = USE_CUDA\n",
    "        if USE_CUDA:\n",
    "            self.DQN = self.DQN.cuda()\n",
    "            self.DQN_target = self.DQN_target.cuda()\n",
    "        self.optimizer = optim.RMSprop(self.DQN.parameters(),lr=lr, eps=0.001, alpha=0.95)\n",
    "\n",
    "    def observe(self, lazyframe):\n",
    "        # from Lazy frame to tensor\n",
    "        state =  torch.from_numpy(lazyframe._force().transpose(2,0,1)[None]/255).float()\n",
    "        if self.USE_CUDA:\n",
    "            state = state.cuda()\n",
    "        return state\n",
    "\n",
    "    def value(self, state):\n",
    "        q_values = self.DQN(state)\n",
    "        return q_values\n",
    "    \n",
    "    def act(self, state, epsilon = None):\n",
    "        \"\"\"\n",
    "        sample actions with epsilon-greedy policy\n",
    "        recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
    "        \"\"\"\n",
    "        if epsilon is None: epsilon = self.epsilon\n",
    "\n",
    "        q_values = self.value(state).cpu().detach().numpy()\n",
    "        if random.random()<epsilon:\n",
    "            aciton = random.randrange(self.action_space.n)\n",
    "        else:\n",
    "            aciton = q_values.argmax(1)[0]\n",
    "        return aciton\n",
    "    \n",
    "    def compute_td_loss(self, states, actions, rewards, next_states, is_done, gamma=0.99):\n",
    "        \"\"\" Compute td loss using torch operations only. Use the formula above. \"\"\"\n",
    "        actions = torch.tensor(actions).long()    # shape: [batch_size]\n",
    "        rewards = torch.tensor(rewards, dtype =torch.float)  # shape: [batch_size]\n",
    "        is_done = torch.tensor(is_done, dtype = torch.uint8)  # shape: [batch_size]\n",
    "        \n",
    "        if self.USE_CUDA:\n",
    "            actions = actions.cuda()\n",
    "            rewards = rewards.cuda()\n",
    "            is_done = is_done.cuda()\n",
    "\n",
    "        # get q-values for all actions in current states\n",
    "        predicted_qvalues = self.DQN(states)   #[32,action]\n",
    "#         print(\"predicted_qvalues:\",predicted_qvalues)\n",
    "#         input()\n",
    "        # select q-values for chosen actions\n",
    "        predicted_qvalues_for_actions = predicted_qvalues[\n",
    "          range(states.shape[0]), actions\n",
    "        ]\n",
    "#         print(\"predicted_qvalues_for_actions:\",predicted_qvalues_for_actions)\n",
    "#         input()\n",
    "        # compute q-values for all actions in next states\n",
    "        predicted_next_qvalues = self.DQN_target(next_states) \n",
    "\n",
    "        # compute V*(next_states) using predicted next q-values\n",
    "        next_state_values =  predicted_next_qvalues.max(-1)[0] \n",
    "\n",
    "        # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "        target_qvalues_for_actions = rewards + gamma *next_state_values \n",
    "\n",
    "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "        target_qvalues_for_actions = torch.where(\n",
    "            is_done, rewards, target_qvalues_for_actions)\n",
    "\n",
    "        # mean squared error loss to minimize\n",
    "        #loss = torch.mean((predicted_qvalues_for_actions -\n",
    "        #                   target_qvalues_for_actions.detach()) ** 2)\n",
    "        loss = F.smooth_l1_loss(predicted_qvalues_for_actions, target_qvalues_for_actions.detach())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def sample_from_buffer(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randint(0, self.memory_buffer.size() - 1)\n",
    "            data = self.memory_buffer.buffer[idx]\n",
    "            frame, action, reward, next_frame, done= data\n",
    "            states.append(self.observe(frame))\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(self.observe(next_frame))\n",
    "            dones.append(done)\n",
    "        return torch.cat(states), actions, rewards, torch.cat(next_states), dones\n",
    "\n",
    "    def learn_from_experience(self, batch_size):\n",
    "        if self.memory_buffer.size() > batch_size:\n",
    "            states, actions, rewards, next_states, dones = self.sample_from_buffer(batch_size)\n",
    "            td_loss = self.compute_td_loss(states, actions, rewards, next_states, dones)\n",
    "            self.optimizer.zero_grad()\n",
    "            td_loss.backward()\n",
    "            for param in self.DQN.parameters():\n",
    "                param.grad.data.clamp_(-1, 1) #梯度截断，防止梯度爆炸\n",
    "\n",
    "            self.optimizer.step()\n",
    "            return(td_loss.item())\n",
    "        else:\n",
    "            return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ouyangz/.conda/envs/gym/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ouyangz/.conda/envs/gym/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:root:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames:     0, reward:   nan, loss: 0.000000, epsilon: 1.000000, episode:    0\n",
      "frames:  1000, reward: -21.000000, loss: 0.000000, epsilon: 0.967544, episode:    1\n",
      "frames:  2000, reward: -21.000000, loss: 0.000000, epsilon: 0.936152, episode:    2\n",
      "frames:  3000, reward: -21.000000, loss: 0.000000, epsilon: 0.905789, episode:    3\n",
      "frames:  4000, reward: -20.250000, loss: 0.000000, epsilon: 0.876422, episode:    4\n",
      "frames:  5000, reward: -20.400000, loss: 0.000000, epsilon: 0.848017, episode:    5\n",
      "frames:  6000, reward: -20.500000, loss: 0.000000, epsilon: 0.820543, episode:    6\n",
      "frames:  7000, reward: -20.625000, loss: 0.000000, epsilon: 0.793971, episode:    8\n",
      "frames:  8000, reward: -20.666667, loss: 0.000000, epsilon: 0.768269, episode:    9\n",
      "frames:  9000, reward: -20.700000, loss: 0.000000, epsilon: 0.743410, episode:   10\n",
      "frames: 10000, reward: -20.700000, loss: 0.000421, epsilon: 0.719366, episode:   12\n",
      "frames: 11000, reward: -20.700000, loss: 0.015133, epsilon: 0.696110, episode:   13\n",
      "frames: 12000, reward: -21.000000, loss: 0.000272, epsilon: 0.673617, episode:   14\n",
      "frames: 13000, reward: -21.000000, loss: 0.015397, epsilon: 0.651861, episode:   15\n",
      "frames: 14000, reward: -20.800000, loss: 0.030306, epsilon: 0.630818, episode:   16\n",
      "frames: 15000, reward: -20.800000, loss: 0.043362, epsilon: 0.610465, episode:   17\n",
      "frames: 16000, reward: -20.700000, loss: 0.000646, epsilon: 0.590780, episode:   18\n",
      "frames: 17000, reward: -20.600000, loss: 0.000400, epsilon: 0.571740, episode:   19\n",
      "frames: 18000, reward: -20.400000, loss: 0.015252, epsilon: 0.553324, episode:   20\n",
      "frames: 19000, reward: -20.400000, loss: 0.000116, epsilon: 0.535511, episode:   21\n",
      "frames: 20000, reward: -20.400000, loss: 0.030551, epsilon: 0.518283, episode:   23\n",
      "frames: 21000, reward: -20.400000, loss: 0.014872, epsilon: 0.501619, episode:   24\n",
      "frames: 22000, reward: -20.400000, loss: 0.000228, epsilon: 0.485502, episode:   25\n",
      "frames: 23000, reward: -20.600000, loss: 0.046605, epsilon: 0.469913, episode:   26\n",
      "frames: 24000, reward: -20.600000, loss: 0.000176, epsilon: 0.454836, episode:   27\n",
      "frames: 25000, reward: -20.700000, loss: 0.000074, epsilon: 0.440252, episode:   28\n",
      "frames: 26000, reward: -20.700000, loss: 0.014424, epsilon: 0.426147, episode:   29\n",
      "frames: 27000, reward: -20.900000, loss: 0.015029, epsilon: 0.412504, episode:   30\n",
      "frames: 28000, reward: -20.900000, loss: 0.000055, epsilon: 0.399308, episode:   32\n",
      "frames: 29000, reward: -20.800000, loss: 0.014605, epsilon: 0.386545, episode:   33\n",
      "frames: 30000, reward: -20.800000, loss: 0.000159, epsilon: 0.374201, episode:   34\n",
      "frames: 31000, reward: -20.800000, loss: 0.000255, epsilon: 0.362261, episode:   35\n",
      "frames: 32000, reward: -20.700000, loss: 0.029854, epsilon: 0.350712, episode:   36\n",
      "frames: 33000, reward: -20.700000, loss: 0.014737, epsilon: 0.339542, episode:   38\n",
      "frames: 34000, reward: -20.800000, loss: 0.000235, epsilon: 0.328739, episode:   39\n",
      "frames: 35000, reward: -20.800000, loss: 0.000463, epsilon: 0.318289, episode:   40\n",
      "frames: 36000, reward: -20.800000, loss: 0.015462, epsilon: 0.308182, episode:   41\n",
      "frames: 37000, reward: -20.800000, loss: 0.030287, epsilon: 0.298407, episode:   42\n",
      "frames: 38000, reward: -20.900000, loss: 0.000077, epsilon: 0.288952, episode:   44\n",
      "frames: 39000, reward: -20.800000, loss: 0.029502, epsilon: 0.279806, episode:   45\n",
      "frames: 40000, reward: -20.800000, loss: 0.001710, epsilon: 0.270961, episode:   46\n",
      "frames: 41000, reward: -20.800000, loss: 0.029162, epsilon: 0.262406, episode:   47\n",
      "frames: 42000, reward: -20.800000, loss: 0.015645, epsilon: 0.254131, episode:   48\n",
      "frames: 43000, reward: -20.800000, loss: 0.030856, epsilon: 0.246127, episode:   49\n",
      "frames: 44000, reward: -20.800000, loss: 0.015076, epsilon: 0.238386, episode:   50\n",
      "frames: 45000, reward: -20.700000, loss: 0.014441, epsilon: 0.230899, episode:   51\n",
      "frames: 46000, reward: -20.600000, loss: 0.042437, epsilon: 0.223657, episode:   53\n",
      "frames: 47000, reward: -20.600000, loss: 0.014151, epsilon: 0.216652, episode:   54\n",
      "frames: 48000, reward: -20.700000, loss: 0.000844, epsilon: 0.209878, episode:   55\n",
      "frames: 49000, reward: -20.800000, loss: 0.001410, epsilon: 0.203325, episode:   56\n",
      "frames: 50000, reward: -20.700000, loss: 0.006902, epsilon: 0.196987, episode:   57\n",
      "frames: 51000, reward: -20.700000, loss: 0.001723, epsilon: 0.190857, episode:   59\n",
      "frames: 52000, reward: -20.600000, loss: 0.012655, epsilon: 0.184928, episode:   60\n",
      "frames: 53000, reward: -20.700000, loss: 0.002603, epsilon: 0.179193, episode:   61\n",
      "frames: 54000, reward: -20.700000, loss: 0.001768, epsilon: 0.173646, episode:   62\n",
      "frames: 55000, reward: -20.700000, loss: 0.001233, epsilon: 0.168281, episode:   63\n",
      "frames: 56000, reward: -20.500000, loss: 0.001927, epsilon: 0.163092, episode:   64\n",
      "frames: 57000, reward: -20.300000, loss: 0.001436, epsilon: 0.158073, episode:   65\n",
      "frames: 58000, reward: -20.300000, loss: 0.003711, epsilon: 0.153219, episode:   66\n",
      "frames: 59000, reward: -20.300000, loss: 0.002104, epsilon: 0.148523, episode:   67\n",
      "frames: 60000, reward: -20.100000, loss: 0.002229, epsilon: 0.143982, episode:   68\n",
      "frames: 61000, reward: -20.100000, loss: 0.002147, epsilon: 0.139589, episode:   69\n",
      "frames: 62000, reward: -20.200000, loss: 0.002383, epsilon: 0.135341, episode:   70\n",
      "frames: 63000, reward: -20.100000, loss: 0.004270, epsilon: 0.131232, episode:   71\n",
      "frames: 64000, reward: -20.200000, loss: 0.002376, epsilon: 0.127257, episode:   73\n",
      "frames: 65000, reward: -20.400000, loss: 0.002143, epsilon: 0.123413, episode:   74\n",
      "frames: 66000, reward: -20.500000, loss: 0.001364, epsilon: 0.119695, episode:   75\n",
      "frames: 67000, reward: -20.500000, loss: 0.001179, epsilon: 0.116099, episode:   76\n",
      "frames: 68000, reward: -20.600000, loss: 0.005261, epsilon: 0.112621, episode:   77\n",
      "frames: 69000, reward: -20.800000, loss: 0.002098, epsilon: 0.109256, episode:   78\n",
      "frames: 70000, reward: -20.600000, loss: 0.002097, epsilon: 0.106002, episode:   79\n",
      "frames: 71000, reward: -20.400000, loss: 0.003649, epsilon: 0.102855, episode:   80\n",
      "frames: 72000, reward: -20.500000, loss: 0.001876, epsilon: 0.099811, episode:   81\n",
      "frames: 73000, reward: -20.400000, loss: 0.004096, epsilon: 0.096866, episode:   82\n",
      "frames: 74000, reward: -20.400000, loss: 0.003736, epsilon: 0.094019, episode:   83\n",
      "frames: 75000, reward: -20.300000, loss: 0.003446, epsilon: 0.091264, episode:   84\n",
      "frames: 76000, reward: -20.300000, loss: 0.005255, epsilon: 0.088600, episode:   85\n",
      "frames: 77000, reward: -20.200000, loss: 0.004422, epsilon: 0.086023, episode:   86\n",
      "frames: 78000, reward: -20.000000, loss: 0.002275, epsilon: 0.083531, episode:   87\n",
      "frames: 79000, reward: -20.000000, loss: 0.001551, epsilon: 0.081120, episode:   87\n",
      "frames: 80000, reward: -20.100000, loss: 0.001108, epsilon: 0.078789, episode:   89\n",
      "frames: 81000, reward: -20.300000, loss: 0.003144, epsilon: 0.076533, episode:   90\n",
      "frames: 82000, reward: -20.300000, loss: 0.004096, epsilon: 0.074352, episode:   90\n",
      "frames: 83000, reward: -19.800000, loss: 0.001373, epsilon: 0.072243, episode:   91\n",
      "frames: 84000, reward: -19.600000, loss: 0.000942, epsilon: 0.070202, episode:   92\n",
      "frames: 85000, reward: -19.500000, loss: 0.007452, epsilon: 0.068228, episode:   93\n",
      "frames: 86000, reward: -19.500000, loss: 0.000963, epsilon: 0.066319, episode:   93\n",
      "frames: 87000, reward: -19.400000, loss: 0.003870, epsilon: 0.064473, episode:   94\n",
      "frames: 88000, reward: -19.500000, loss: 0.002139, epsilon: 0.062687, episode:   95\n",
      "frames: 89000, reward: -19.600000, loss: 0.001468, epsilon: 0.060960, episode:   96\n",
      "frames: 90000, reward: -19.800000, loss: 0.001888, epsilon: 0.059289, episode:   97\n",
      "frames: 91000, reward: -19.600000, loss: 0.005154, epsilon: 0.057673, episode:   98\n",
      "frames: 92000, reward: -19.500000, loss: 0.001249, epsilon: 0.056110, episode:   99\n",
      "frames: 93000, reward: -19.500000, loss: 0.001548, epsilon: 0.054599, episode:  100\n",
      "frames: 94000, reward: -19.900000, loss: 0.001167, epsilon: 0.053137, episode:  101\n",
      "frames: 95000, reward: -19.900000, loss: 0.006702, epsilon: 0.051722, episode:  102\n",
      "frames: 96000, reward: -19.900000, loss: 0.005428, epsilon: 0.050355, episode:  103\n",
      "frames: 97000, reward: -20.100000, loss: 0.001544, epsilon: 0.049032, episode:  104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 98000, reward: -20.100000, loss: 0.002504, epsilon: 0.047752, episode:  104\n",
      "frames: 99000, reward: -19.900000, loss: 0.001221, epsilon: 0.046514, episode:  105\n",
      "frames: 100000, reward: -19.800000, loss: 0.004040, epsilon: 0.045317, episode:  106\n",
      "frames: 101000, reward: -19.300000, loss: 0.015730, epsilon: 0.044159, episode:  107\n",
      "frames: 102000, reward: -19.300000, loss: 0.001668, epsilon: 0.043040, episode:  107\n",
      "frames: 103000, reward: -19.200000, loss: 0.003280, epsilon: 0.041956, episode:  108\n",
      "frames: 104000, reward: -19.000000, loss: 0.006486, epsilon: 0.040909, episode:  109\n",
      "frames: 105000, reward: -19.000000, loss: 0.001416, epsilon: 0.039895, episode:  109\n",
      "frames: 106000, reward: -18.900000, loss: 0.002020, epsilon: 0.038915, episode:  110\n",
      "frames: 107000, reward: -19.000000, loss: 0.003285, epsilon: 0.037967, episode:  111\n",
      "frames: 108000, reward: -19.300000, loss: 0.002000, epsilon: 0.037050, episode:  112\n",
      "frames: 109000, reward: -19.100000, loss: 0.002524, epsilon: 0.036164, episode:  113\n",
      "frames: 110000, reward: -18.700000, loss: 0.004051, epsilon: 0.035306, episode:  114\n",
      "frames: 111000, reward: -18.700000, loss: 0.002033, epsilon: 0.034476, episode:  114\n",
      "frames: 112000, reward: -18.700000, loss: 0.001866, epsilon: 0.033674, episode:  115\n",
      "frames: 113000, reward: -18.700000, loss: 0.002524, epsilon: 0.032898, episode:  115\n",
      "frames: 114000, reward: -18.700000, loss: 0.002251, epsilon: 0.032147, episode:  116\n",
      "frames: 115000, reward: -19.000000, loss: 0.001288, epsilon: 0.031421, episode:  117\n",
      "frames: 116000, reward: -19.200000, loss: 0.001996, epsilon: 0.030719, episode:  118\n",
      "frames: 117000, reward: -19.200000, loss: 0.002295, epsilon: 0.030039, episode:  118\n",
      "frames: 118000, reward: -19.400000, loss: 0.001637, epsilon: 0.029383, episode:  119\n",
      "frames: 119000, reward: -19.300000, loss: 0.003434, epsilon: 0.028747, episode:  120\n",
      "frames: 120000, reward: -19.000000, loss: 0.002024, epsilon: 0.028132, episode:  121\n",
      "frames: 121000, reward: -19.000000, loss: 0.001790, epsilon: 0.027538, episode:  121\n",
      "frames: 122000, reward: -18.700000, loss: 0.002240, epsilon: 0.026963, episode:  122\n",
      "frames: 123000, reward: -18.700000, loss: 0.003541, epsilon: 0.026407, episode:  122\n",
      "frames: 124000, reward: -18.700000, loss: 0.004921, epsilon: 0.025869, episode:  123\n",
      "frames: 125000, reward: -19.000000, loss: 0.002040, epsilon: 0.025349, episode:  124\n",
      "frames: 126000, reward: -19.100000, loss: 0.004473, epsilon: 0.024846, episode:  125\n",
      "frames: 127000, reward: -19.100000, loss: 0.005874, epsilon: 0.024359, episode:  125\n",
      "frames: 128000, reward: -19.000000, loss: 0.007684, epsilon: 0.023888, episode:  126\n",
      "frames: 129000, reward: -19.000000, loss: 0.003911, epsilon: 0.023433, episode:  126\n",
      "frames: 130000, reward: -19.000000, loss: 0.002063, epsilon: 0.022992, episode:  127\n",
      "frames: 131000, reward: -19.200000, loss: 0.002505, epsilon: 0.022567, episode:  128\n",
      "frames: 132000, reward: -19.200000, loss: 0.002021, epsilon: 0.022155, episode:  129\n",
      "frames: 133000, reward: -19.200000, loss: 0.005014, epsilon: 0.021756, episode:  129\n",
      "frames: 134000, reward: -19.200000, loss: 0.002244, epsilon: 0.021371, episode:  130\n",
      "frames: 135000, reward: -19.200000, loss: 0.001675, epsilon: 0.020998, episode:  130\n",
      "frames: 136000, reward: -19.200000, loss: 0.001136, epsilon: 0.020637, episode:  130\n",
      "frames: 137000, reward: -19.100000, loss: 0.003022, epsilon: 0.020289, episode:  131\n",
      "frames: 138000, reward: -18.800000, loss: 0.002173, epsilon: 0.019951, episode:  132\n",
      "frames: 139000, reward: -18.800000, loss: 0.001518, epsilon: 0.019625, episode:  132\n",
      "frames: 140000, reward: -18.800000, loss: 0.003841, epsilon: 0.019310, episode:  132\n",
      "frames: 141000, reward: -18.300000, loss: 0.003262, epsilon: 0.019004, episode:  133\n",
      "frames: 142000, reward: -18.300000, loss: 0.009869, epsilon: 0.018709, episode:  133\n",
      "frames: 143000, reward: -18.000000, loss: 0.003209, epsilon: 0.018424, episode:  134\n",
      "frames: 144000, reward: -18.000000, loss: 0.001014, epsilon: 0.018147, episode:  134\n",
      "frames: 145000, reward: -17.700000, loss: 0.001296, epsilon: 0.017880, episode:  135\n",
      "frames: 146000, reward: -17.700000, loss: 0.007859, epsilon: 0.017622, episode:  135\n",
      "frames: 147000, reward: -17.600000, loss: 0.000999, epsilon: 0.017372, episode:  136\n",
      "frames: 148000, reward: -17.600000, loss: 0.001805, epsilon: 0.017130, episode:  136\n",
      "frames: 149000, reward: -17.600000, loss: 0.002608, epsilon: 0.016897, episode:  137\n",
      "frames: 150000, reward: -17.600000, loss: 0.001919, epsilon: 0.016671, episode:  137\n",
      "frames: 151000, reward: -17.100000, loss: 0.000897, epsilon: 0.016452, episode:  138\n",
      "frames: 152000, reward: -17.100000, loss: 0.001427, epsilon: 0.016240, episode:  138\n",
      "frames: 153000, reward: -17.100000, loss: 0.001918, epsilon: 0.016036, episode:  139\n",
      "frames: 154000, reward: -17.100000, loss: 0.001257, epsilon: 0.015838, episode:  139\n",
      "frames: 155000, reward: -16.900000, loss: 0.003719, epsilon: 0.015647, episode:  140\n",
      "frames: 156000, reward: -16.900000, loss: 0.002425, epsilon: 0.015461, episode:  140\n",
      "frames: 157000, reward: -16.900000, loss: 0.003676, epsilon: 0.015282, episode:  140\n",
      "frames: 158000, reward: -16.500000, loss: 0.001602, epsilon: 0.015109, episode:  141\n",
      "frames: 159000, reward: -16.500000, loss: 0.001348, epsilon: 0.014942, episode:  141\n",
      "frames: 160000, reward: -16.900000, loss: 0.004923, epsilon: 0.014780, episode:  142\n",
      "frames: 161000, reward: -16.900000, loss: 0.001708, epsilon: 0.014623, episode:  142\n",
      "frames: 162000, reward: -17.200000, loss: 0.001005, epsilon: 0.014471, episode:  143\n",
      "frames: 163000, reward: -17.200000, loss: 0.002378, epsilon: 0.014325, episode:  143\n",
      "frames: 164000, reward: -16.700000, loss: 0.001546, epsilon: 0.014183, episode:  144\n",
      "frames: 165000, reward: -16.900000, loss: 0.001213, epsilon: 0.014046, episode:  145\n",
      "frames: 166000, reward: -16.900000, loss: 0.003404, epsilon: 0.013913, episode:  145\n",
      "frames: 167000, reward: -17.100000, loss: 0.004224, epsilon: 0.013785, episode:  146\n",
      "frames: 168000, reward: -17.100000, loss: 0.000503, epsilon: 0.013661, episode:  146\n",
      "frames: 169000, reward: -17.000000, loss: 0.001046, epsilon: 0.013541, episode:  147\n",
      "frames: 170000, reward: -17.000000, loss: 0.001759, epsilon: 0.013425, episode:  147\n",
      "frames: 171000, reward: -16.600000, loss: 0.002509, epsilon: 0.013313, episode:  148\n",
      "frames: 172000, reward: -16.600000, loss: 0.001555, epsilon: 0.013204, episode:  148\n",
      "frames: 173000, reward: -16.600000, loss: 0.009538, epsilon: 0.013099, episode:  148\n",
      "frames: 174000, reward: -15.700000, loss: 0.000723, epsilon: 0.012997, episode:  149\n",
      "frames: 175000, reward: -15.700000, loss: 0.001662, epsilon: 0.012899, episode:  149\n",
      "frames: 176000, reward: -15.700000, loss: 0.000976, epsilon: 0.012804, episode:  149\n",
      "frames: 177000, reward: -15.100000, loss: 0.003580, epsilon: 0.012712, episode:  150\n",
      "frames: 178000, reward: -15.100000, loss: 0.002588, epsilon: 0.012623, episode:  150\n",
      "frames: 179000, reward: -15.100000, loss: 0.002244, epsilon: 0.012537, episode:  150\n",
      "frames: 180000, reward: -14.600000, loss: 0.002706, epsilon: 0.012454, episode:  151\n",
      "frames: 181000, reward: -14.600000, loss: 0.001738, epsilon: 0.012374, episode:  151\n",
      "frames: 182000, reward: -14.600000, loss: 0.001859, epsilon: 0.012296, episode:  151\n",
      "frames: 183000, reward: -14.100000, loss: 0.005237, epsilon: 0.012220, episode:  152\n",
      "frames: 184000, reward: -14.100000, loss: 0.002121, epsilon: 0.012148, episode:  152\n",
      "frames: 185000, reward: -14.000000, loss: 0.001858, epsilon: 0.012077, episode:  153\n",
      "frames: 186000, reward: -14.000000, loss: 0.001690, epsilon: 0.012009, episode:  153\n",
      "frames: 187000, reward: -14.000000, loss: 0.000661, epsilon: 0.011943, episode:  153\n",
      "frames: 188000, reward: -14.000000, loss: 0.001987, epsilon: 0.011880, episode:  154\n",
      "frames: 189000, reward: -14.000000, loss: 0.001899, epsilon: 0.011818, episode:  154\n",
      "frames: 190000, reward: -14.000000, loss: 0.002682, epsilon: 0.011758, episode:  154\n",
      "frames: 191000, reward: -13.000000, loss: 0.008496, epsilon: 0.011701, episode:  155\n",
      "frames: 192000, reward: -13.000000, loss: 0.002024, epsilon: 0.011645, episode:  155\n",
      "frames: 193000, reward: -12.900000, loss: 0.019027, epsilon: 0.011591, episode:  156\n",
      "frames: 194000, reward: -12.900000, loss: 0.001755, epsilon: 0.011539, episode:  156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 195000, reward: -12.700000, loss: 0.007836, epsilon: 0.011488, episode:  157\n",
      "frames: 196000, reward: -12.700000, loss: 0.002527, epsilon: 0.011440, episode:  157\n",
      "frames: 197000, reward: -12.700000, loss: 0.003091, epsilon: 0.011392, episode:  157\n",
      "frames: 198000, reward: -12.600000, loss: 0.011150, epsilon: 0.011347, episode:  158\n",
      "frames: 199000, reward: -13.400000, loss: 0.002067, epsilon: 0.011303, episode:  159\n",
      "frames: 200000, reward: -13.400000, loss: 0.004269, epsilon: 0.011260, episode:  159\n",
      "frames: 201000, reward: -14.300000, loss: 0.004734, epsilon: 0.011219, episode:  160\n",
      "frames: 202000, reward: -14.300000, loss: 0.001433, epsilon: 0.011179, episode:  160\n",
      "frames: 203000, reward: -14.300000, loss: 0.001893, epsilon: 0.011140, episode:  160\n",
      "frames: 204000, reward: -15.400000, loss: 0.002712, epsilon: 0.011103, episode:  161\n",
      "frames: 205000, reward: -15.400000, loss: 0.002268, epsilon: 0.011066, episode:  161\n",
      "frames: 206000, reward: -15.400000, loss: 0.004169, epsilon: 0.011032, episode:  161\n",
      "frames: 207000, reward: -15.400000, loss: 0.001452, epsilon: 0.010998, episode:  161\n",
      "frames: 208000, reward: -15.200000, loss: 0.001442, epsilon: 0.010965, episode:  162\n",
      "frames: 209000, reward: -15.200000, loss: 0.001445, epsilon: 0.010933, episode:  162\n",
      "frames: 210000, reward: -15.100000, loss: 0.002677, epsilon: 0.010903, episode:  163\n",
      "frames: 211000, reward: -15.100000, loss: 0.001637, epsilon: 0.010873, episode:  163\n",
      "frames: 212000, reward: -15.100000, loss: 0.000977, epsilon: 0.010845, episode:  163\n",
      "frames: 213000, reward: -15.100000, loss: 0.002871, epsilon: 0.010817, episode:  163\n",
      "frames: 214000, reward: -15.200000, loss: 0.001237, epsilon: 0.010790, episode:  164\n",
      "frames: 215000, reward: -15.200000, loss: 0.001450, epsilon: 0.010764, episode:  164\n",
      "frames: 216000, reward: -15.200000, loss: 0.002028, epsilon: 0.010739, episode:  164\n",
      "frames: 217000, reward: -15.700000, loss: 0.000909, epsilon: 0.010715, episode:  165\n",
      "frames: 218000, reward: -15.700000, loss: 0.001786, epsilon: 0.010691, episode:  165\n",
      "frames: 219000, reward: -15.700000, loss: 0.000851, epsilon: 0.010669, episode:  165\n",
      "frames: 220000, reward: -15.700000, loss: 0.001109, epsilon: 0.010647, episode:  165\n",
      "frames: 221000, reward: -15.200000, loss: 0.001011, epsilon: 0.010626, episode:  166\n",
      "frames: 222000, reward: -15.200000, loss: 0.000551, epsilon: 0.010605, episode:  166\n",
      "frames: 223000, reward: -15.100000, loss: 0.000782, epsilon: 0.010585, episode:  167\n",
      "frames: 224000, reward: -15.100000, loss: 0.001601, epsilon: 0.010566, episode:  167\n",
      "frames: 225000, reward: -15.100000, loss: 0.002617, epsilon: 0.010548, episode:  167\n",
      "frames: 226000, reward: -15.000000, loss: 0.000744, epsilon: 0.010530, episode:  168\n",
      "frames: 227000, reward: -15.000000, loss: 0.001085, epsilon: 0.010512, episode:  168\n",
      "frames: 228000, reward: -15.000000, loss: 0.001206, epsilon: 0.010495, episode:  168\n",
      "frames: 229000, reward: -14.400000, loss: 0.001749, epsilon: 0.010479, episode:  169\n",
      "frames: 230000, reward: -14.400000, loss: 0.000527, epsilon: 0.010463, episode:  169\n",
      "frames: 231000, reward: -14.400000, loss: 0.001435, epsilon: 0.010448, episode:  169\n",
      "frames: 232000, reward: -14.000000, loss: 0.000648, epsilon: 0.010434, episode:  170\n",
      "frames: 233000, reward: -14.000000, loss: 0.001254, epsilon: 0.010419, episode:  170\n",
      "frames: 234000, reward: -13.400000, loss: 0.002097, epsilon: 0.010406, episode:  171\n",
      "frames: 235000, reward: -13.400000, loss: 0.006808, epsilon: 0.010392, episode:  171\n",
      "frames: 236000, reward: -13.400000, loss: 0.022825, epsilon: 0.010379, episode:  171\n",
      "frames: 237000, reward: -13.200000, loss: 0.002224, epsilon: 0.010367, episode:  172\n",
      "frames: 238000, reward: -13.200000, loss: 0.001091, epsilon: 0.010355, episode:  172\n",
      "frames: 239000, reward: -13.100000, loss: 0.001236, epsilon: 0.010343, episode:  173\n",
      "frames: 240000, reward: -13.100000, loss: 0.004160, epsilon: 0.010332, episode:  173\n",
      "frames: 241000, reward: -13.100000, loss: 0.002898, epsilon: 0.010321, episode:  173\n",
      "frames: 242000, reward: -12.800000, loss: 0.001631, epsilon: 0.010311, episode:  174\n",
      "frames: 243000, reward: -12.800000, loss: 0.001141, epsilon: 0.010301, episode:  174\n",
      "frames: 244000, reward: -12.800000, loss: 0.000646, epsilon: 0.010291, episode:  174\n",
      "frames: 245000, reward: -12.800000, loss: 0.001035, epsilon: 0.010281, episode:  174\n",
      "frames: 246000, reward: -12.400000, loss: 0.001851, epsilon: 0.010272, episode:  175\n",
      "frames: 247000, reward: -12.400000, loss: 0.002329, epsilon: 0.010263, episode:  175\n",
      "frames: 248000, reward: -12.400000, loss: 0.001765, epsilon: 0.010254, episode:  175\n",
      "frames: 249000, reward: -12.100000, loss: 0.001080, epsilon: 0.010246, episode:  176\n",
      "frames: 250000, reward: -12.100000, loss: 0.000966, epsilon: 0.010238, episode:  176\n",
      "frames: 251000, reward: -12.100000, loss: 0.001516, epsilon: 0.010230, episode:  176\n",
      "frames: 252000, reward: -11.600000, loss: 0.001706, epsilon: 0.010223, episode:  177\n",
      "frames: 253000, reward: -11.600000, loss: 0.002463, epsilon: 0.010215, episode:  177\n",
      "frames: 254000, reward: -11.600000, loss: 0.001152, epsilon: 0.010208, episode:  177\n",
      "frames: 255000, reward: -11.600000, loss: 0.001101, epsilon: 0.010201, episode:  178\n",
      "frames: 256000, reward: -11.600000, loss: 0.001526, epsilon: 0.010195, episode:  178\n",
      "frames: 257000, reward: -11.600000, loss: 0.000962, epsilon: 0.010188, episode:  178\n",
      "frames: 258000, reward: -11.600000, loss: 0.002772, epsilon: 0.010182, episode:  178\n",
      "frames: 259000, reward: -11.200000, loss: 0.001368, epsilon: 0.010176, episode:  179\n",
      "frames: 260000, reward: -11.200000, loss: 0.001745, epsilon: 0.010171, episode:  179\n",
      "frames: 261000, reward: -11.200000, loss: 0.002186, epsilon: 0.010165, episode:  179\n",
      "frames: 262000, reward: -11.200000, loss: 0.005436, epsilon: 0.010160, episode:  179\n",
      "frames: 263000, reward: -11.200000, loss: 0.000884, epsilon: 0.010154, episode:  179\n",
      "frames: 264000, reward: -9.700000, loss: 0.001315, epsilon: 0.010149, episode:  180\n",
      "frames: 265000, reward: -9.700000, loss: 0.000758, epsilon: 0.010144, episode:  180\n",
      "frames: 266000, reward: -9.700000, loss: 0.001077, epsilon: 0.010140, episode:  180\n",
      "frames: 267000, reward: -9.400000, loss: 0.000764, epsilon: 0.010135, episode:  181\n",
      "frames: 268000, reward: -9.400000, loss: 0.000865, epsilon: 0.010131, episode:  181\n",
      "frames: 269000, reward: -9.400000, loss: 0.001646, epsilon: 0.010126, episode:  181\n",
      "frames: 270000, reward: -9.400000, loss: 0.003228, epsilon: 0.010122, episode:  181\n",
      "frames: 271000, reward: -9.600000, loss: 0.000796, epsilon: 0.010118, episode:  182\n",
      "frames: 272000, reward: -9.600000, loss: 0.000584, epsilon: 0.010114, episode:  182\n",
      "frames: 273000, reward: -9.600000, loss: 0.000892, epsilon: 0.010111, episode:  182\n",
      "frames: 274000, reward: -9.600000, loss: 0.001005, epsilon: 0.010107, episode:  182\n",
      "frames: 275000, reward: -9.400000, loss: 0.001458, epsilon: 0.010103, episode:  183\n",
      "frames: 276000, reward: -9.400000, loss: 0.001358, epsilon: 0.010100, episode:  183\n",
      "frames: 277000, reward: -9.400000, loss: 0.002483, epsilon: 0.010097, episode:  183\n",
      "frames: 278000, reward: -9.400000, loss: 0.000855, epsilon: 0.010094, episode:  183\n",
      "frames: 279000, reward: -9.300000, loss: 0.003263, epsilon: 0.010091, episode:  184\n",
      "frames: 280000, reward: -9.300000, loss: 0.001763, epsilon: 0.010088, episode:  184\n",
      "frames: 281000, reward: -9.300000, loss: 0.001392, epsilon: 0.010085, episode:  184\n",
      "frames: 282000, reward: -9.800000, loss: 0.000426, epsilon: 0.010082, episode:  185\n",
      "frames: 283000, reward: -9.800000, loss: 0.003521, epsilon: 0.010079, episode:  185\n",
      "frames: 284000, reward: -9.800000, loss: 0.000675, epsilon: 0.010077, episode:  185\n",
      "frames: 285000, reward: -9.800000, loss: 0.000930, epsilon: 0.010074, episode:  185\n",
      "frames: 286000, reward: -9.400000, loss: 0.002802, epsilon: 0.010072, episode:  186\n",
      "frames: 287000, reward: -9.400000, loss: 0.001724, epsilon: 0.010069, episode:  186\n",
      "frames: 288000, reward: -9.400000, loss: 0.001702, epsilon: 0.010067, episode:  186\n",
      "frames: 289000, reward: -9.400000, loss: 0.000759, epsilon: 0.010065, episode:  186\n",
      "frames: 290000, reward: -10.100000, loss: 0.000593, epsilon: 0.010063, episode:  187\n",
      "frames: 291000, reward: -10.100000, loss: 0.000540, epsilon: 0.010061, episode:  187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 292000, reward: -10.100000, loss: 0.001137, epsilon: 0.010059, episode:  187\n",
      "frames: 293000, reward: -10.100000, loss: 0.000874, epsilon: 0.010057, episode:  187\n",
      "frames: 294000, reward: -10.000000, loss: 0.000973, epsilon: 0.010055, episode:  188\n",
      "frames: 295000, reward: -10.000000, loss: 0.000876, epsilon: 0.010053, episode:  188\n",
      "frames: 296000, reward: -10.000000, loss: 0.001481, epsilon: 0.010051, episode:  188\n",
      "frames: 297000, reward: -10.400000, loss: 0.002080, epsilon: 0.010050, episode:  189\n",
      "frames: 298000, reward: -10.400000, loss: 0.001189, epsilon: 0.010048, episode:  189\n",
      "frames: 299000, reward: -10.400000, loss: 0.000768, epsilon: 0.010046, episode:  189\n",
      "frames: 300000, reward: -10.400000, loss: 0.001110, epsilon: 0.010045, episode:  189\n",
      "frames: 301000, reward: -10.700000, loss: 0.001241, epsilon: 0.010043, episode:  190\n",
      "frames: 302000, reward: -10.700000, loss: 0.002660, epsilon: 0.010042, episode:  190\n",
      "frames: 303000, reward: -10.700000, loss: 0.002544, epsilon: 0.010041, episode:  190\n",
      "frames: 304000, reward: -10.600000, loss: 0.000534, epsilon: 0.010039, episode:  191\n",
      "frames: 305000, reward: -10.600000, loss: 0.002953, epsilon: 0.010038, episode:  191\n",
      "frames: 306000, reward: -10.600000, loss: 0.000834, epsilon: 0.010037, episode:  191\n",
      "frames: 307000, reward: -10.600000, loss: 0.001109, epsilon: 0.010036, episode:  191\n",
      "frames: 308000, reward: -10.200000, loss: 0.002199, epsilon: 0.010034, episode:  192\n",
      "frames: 309000, reward: -10.200000, loss: 0.001271, epsilon: 0.010033, episode:  192\n",
      "frames: 310000, reward: -10.200000, loss: 0.000875, epsilon: 0.010032, episode:  192\n",
      "frames: 311000, reward: -10.100000, loss: 0.001139, epsilon: 0.010031, episode:  193\n",
      "frames: 312000, reward: -10.100000, loss: 0.002533, epsilon: 0.010030, episode:  193\n",
      "frames: 313000, reward: -10.100000, loss: 0.001686, epsilon: 0.010029, episode:  193\n",
      "frames: 314000, reward: -10.100000, loss: 0.000594, epsilon: 0.010028, episode:  193\n",
      "frames: 315000, reward: -9.800000, loss: 0.001968, epsilon: 0.010027, episode:  194\n",
      "frames: 316000, reward: -9.800000, loss: 0.000684, epsilon: 0.010026, episode:  194\n",
      "frames: 317000, reward: -9.800000, loss: 0.002620, epsilon: 0.010026, episode:  194\n",
      "frames: 318000, reward: -9.800000, loss: 0.000687, epsilon: 0.010025, episode:  194\n",
      "frames: 319000, reward: -8.700000, loss: 0.000801, epsilon: 0.010024, episode:  195\n",
      "frames: 320000, reward: -8.700000, loss: 0.001759, epsilon: 0.010023, episode:  195\n",
      "frames: 321000, reward: -8.700000, loss: 0.001311, epsilon: 0.010022, episode:  195\n",
      "frames: 322000, reward: -9.700000, loss: 0.001014, epsilon: 0.010022, episode:  196\n",
      "frames: 323000, reward: -9.700000, loss: 0.001869, epsilon: 0.010021, episode:  196\n",
      "frames: 324000, reward: -9.700000, loss: 0.000886, epsilon: 0.010020, episode:  196\n",
      "frames: 325000, reward: -9.400000, loss: 0.001083, epsilon: 0.010020, episode:  197\n",
      "frames: 326000, reward: -9.400000, loss: 0.000924, epsilon: 0.010019, episode:  197\n",
      "frames: 327000, reward: -9.900000, loss: 0.001025, epsilon: 0.010018, episode:  198\n",
      "frames: 328000, reward: -9.900000, loss: 0.002473, epsilon: 0.010018, episode:  198\n",
      "frames: 329000, reward: -10.400000, loss: 0.000634, epsilon: 0.010017, episode:  199\n",
      "frames: 330000, reward: -10.400000, loss: 0.003486, epsilon: 0.010017, episode:  199\n",
      "frames: 331000, reward: -10.400000, loss: 0.001459, epsilon: 0.010016, episode:  199\n",
      "frames: 332000, reward: -10.400000, loss: 0.000823, epsilon: 0.010015, episode:  199\n",
      "frames: 333000, reward: -10.700000, loss: 0.000986, epsilon: 0.010015, episode:  200\n",
      "frames: 334000, reward: -10.700000, loss: 0.001618, epsilon: 0.010014, episode:  200\n",
      "frames: 335000, reward: -10.700000, loss: 0.000839, epsilon: 0.010014, episode:  200\n",
      "frames: 336000, reward: -10.700000, loss: 0.001116, epsilon: 0.010014, episode:  200\n",
      "frames: 337000, reward: -10.700000, loss: 0.000755, epsilon: 0.010013, episode:  200\n",
      "frames: 338000, reward: -10.600000, loss: 0.001079, epsilon: 0.010013, episode:  201\n",
      "frames: 339000, reward: -10.600000, loss: 0.010140, epsilon: 0.010012, episode:  201\n",
      "frames: 340000, reward: -10.600000, loss: 0.000487, epsilon: 0.010012, episode:  201\n",
      "frames: 341000, reward: -10.600000, loss: 0.002568, epsilon: 0.010011, episode:  202\n",
      "frames: 342000, reward: -10.600000, loss: 0.002684, epsilon: 0.010011, episode:  202\n",
      "frames: 343000, reward: -10.600000, loss: 0.002442, epsilon: 0.010011, episode:  202\n",
      "frames: 344000, reward: -10.600000, loss: 0.000635, epsilon: 0.010010, episode:  202\n",
      "frames: 345000, reward: -10.300000, loss: 0.001255, epsilon: 0.010010, episode:  203\n",
      "frames: 346000, reward: -10.300000, loss: 0.000840, epsilon: 0.010010, episode:  203\n",
      "frames: 347000, reward: -10.300000, loss: 0.000935, epsilon: 0.010009, episode:  203\n",
      "frames: 348000, reward: -10.300000, loss: 0.001973, epsilon: 0.010009, episode:  203\n",
      "frames: 349000, reward: -10.800000, loss: 0.001582, epsilon: 0.010009, episode:  204\n",
      "frames: 350000, reward: -10.800000, loss: 0.001286, epsilon: 0.010008, episode:  204\n",
      "frames: 351000, reward: -10.800000, loss: 0.001183, epsilon: 0.010008, episode:  204\n",
      "frames: 352000, reward: -10.800000, loss: 0.001406, epsilon: 0.010008, episode:  204\n",
      "frames: 353000, reward: -10.800000, loss: 0.001770, epsilon: 0.010008, episode:  204\n",
      "frames: 354000, reward: -11.400000, loss: 0.001185, epsilon: 0.010007, episode:  205\n",
      "frames: 355000, reward: -11.400000, loss: 0.001314, epsilon: 0.010007, episode:  205\n",
      "frames: 356000, reward: -11.400000, loss: 0.001374, epsilon: 0.010007, episode:  205\n",
      "frames: 357000, reward: -10.600000, loss: 0.001853, epsilon: 0.010007, episode:  206\n",
      "frames: 358000, reward: -10.600000, loss: 0.001498, epsilon: 0.010007, episode:  206\n",
      "frames: 359000, reward: -10.600000, loss: 0.002676, epsilon: 0.010006, episode:  206\n",
      "frames: 360000, reward: -10.600000, loss: 0.002185, epsilon: 0.010006, episode:  206\n",
      "frames: 361000, reward: -10.600000, loss: 0.000974, epsilon: 0.010006, episode:  206\n",
      "frames: 362000, reward: -9.600000, loss: 0.006176, epsilon: 0.010006, episode:  207\n",
      "frames: 363000, reward: -9.600000, loss: 0.000627, epsilon: 0.010006, episode:  207\n",
      "frames: 364000, reward: -9.600000, loss: 0.000737, epsilon: 0.010005, episode:  207\n",
      "frames: 365000, reward: -9.600000, loss: 0.000968, epsilon: 0.010005, episode:  207\n",
      "frames: 366000, reward: -7.700000, loss: 0.000474, epsilon: 0.010005, episode:  208\n",
      "frames: 367000, reward: -7.700000, loss: 0.001207, epsilon: 0.010005, episode:  208\n",
      "frames: 368000, reward: -7.700000, loss: 0.000978, epsilon: 0.010005, episode:  208\n",
      "frames: 369000, reward: -7.700000, loss: 0.000614, epsilon: 0.010005, episode:  208\n",
      "frames: 370000, reward: -7.700000, loss: 0.000614, epsilon: 0.010004, episode:  208\n",
      "frames: 371000, reward: -6.700000, loss: 0.000840, epsilon: 0.010004, episode:  209\n",
      "frames: 372000, reward: -6.700000, loss: 0.001332, epsilon: 0.010004, episode:  209\n",
      "frames: 373000, reward: -6.700000, loss: 0.001275, epsilon: 0.010004, episode:  209\n",
      "frames: 374000, reward: -6.700000, loss: 0.000724, epsilon: 0.010004, episode:  209\n",
      "frames: 375000, reward: -6.700000, loss: 0.001204, epsilon: 0.010004, episode:  209\n",
      "frames: 376000, reward: -6.200000, loss: 0.001779, epsilon: 0.010004, episode:  210\n",
      "frames: 377000, reward: -6.200000, loss: 0.002863, epsilon: 0.010003, episode:  210\n",
      "frames: 378000, reward: -6.200000, loss: 0.000659, epsilon: 0.010003, episode:  210\n",
      "frames: 379000, reward: -6.200000, loss: 0.001381, epsilon: 0.010003, episode:  210\n",
      "frames: 380000, reward: -6.200000, loss: 0.001258, epsilon: 0.010003, episode:  210\n",
      "frames: 381000, reward: -5.900000, loss: 0.001942, epsilon: 0.010003, episode:  211\n",
      "frames: 382000, reward: -5.900000, loss: 0.001141, epsilon: 0.010003, episode:  211\n",
      "frames: 383000, reward: -5.900000, loss: 0.001544, epsilon: 0.010003, episode:  211\n",
      "frames: 384000, reward: -5.900000, loss: 0.001013, epsilon: 0.010003, episode:  211\n",
      "frames: 385000, reward: -5.900000, loss: 0.000741, epsilon: 0.010003, episode:  211\n",
      "frames: 386000, reward: -6.100000, loss: 0.001332, epsilon: 0.010003, episode:  212\n",
      "frames: 387000, reward: -6.100000, loss: 0.003397, epsilon: 0.010002, episode:  212\n",
      "frames: 388000, reward: -6.100000, loss: 0.003787, epsilon: 0.010002, episode:  212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 389000, reward: -6.100000, loss: 0.002304, epsilon: 0.010002, episode:  212\n",
      "frames: 390000, reward: -5.800000, loss: 0.000450, epsilon: 0.010002, episode:  213\n",
      "frames: 391000, reward: -5.800000, loss: 0.001590, epsilon: 0.010002, episode:  213\n",
      "frames: 392000, reward: -5.800000, loss: 0.000797, epsilon: 0.010002, episode:  213\n",
      "frames: 393000, reward: -5.800000, loss: 0.002108, epsilon: 0.010002, episode:  213\n",
      "frames: 394000, reward: -5.800000, loss: 0.000958, epsilon: 0.010002, episode:  214\n",
      "frames: 395000, reward: -5.800000, loss: 0.000819, epsilon: 0.010002, episode:  214\n",
      "frames: 396000, reward: -5.800000, loss: 0.000955, epsilon: 0.010002, episode:  214\n",
      "frames: 397000, reward: -6.000000, loss: 0.000471, epsilon: 0.010002, episode:  215\n",
      "frames: 398000, reward: -6.000000, loss: 0.000797, epsilon: 0.010002, episode:  215\n",
      "frames: 399000, reward: -6.000000, loss: 0.000634, epsilon: 0.010002, episode:  215\n",
      "frames: 400000, reward: -6.000000, loss: 0.001001, epsilon: 0.010002, episode:  215\n",
      "frames: 401000, reward: -6.000000, loss: 0.002396, epsilon: 0.010002, episode:  215\n",
      "frames: 402000, reward: -5.500000, loss: 0.000892, epsilon: 0.010001, episode:  216\n",
      "frames: 403000, reward: -5.500000, loss: 0.000807, epsilon: 0.010001, episode:  216\n",
      "frames: 404000, reward: -5.500000, loss: 0.001355, epsilon: 0.010001, episode:  216\n",
      "frames: 405000, reward: -5.500000, loss: 0.001000, epsilon: 0.010001, episode:  216\n",
      "frames: 406000, reward: -5.500000, loss: 0.001069, epsilon: 0.010001, episode:  217\n",
      "frames: 407000, reward: -5.500000, loss: 0.001171, epsilon: 0.010001, episode:  217\n",
      "frames: 408000, reward: -5.500000, loss: 0.001150, epsilon: 0.010001, episode:  217\n",
      "frames: 409000, reward: -5.500000, loss: 0.000809, epsilon: 0.010001, episode:  217\n",
      "frames: 410000, reward: -6.300000, loss: 0.000740, epsilon: 0.010001, episode:  218\n",
      "frames: 411000, reward: -6.300000, loss: 0.001094, epsilon: 0.010001, episode:  218\n",
      "frames: 412000, reward: -6.300000, loss: 0.001643, epsilon: 0.010001, episode:  218\n",
      "frames: 413000, reward: -6.300000, loss: 0.000708, epsilon: 0.010001, episode:  218\n",
      "frames: 414000, reward: -5.200000, loss: 0.001720, epsilon: 0.010001, episode:  219\n",
      "frames: 415000, reward: -5.200000, loss: 0.001310, epsilon: 0.010001, episode:  219\n",
      "frames: 416000, reward: -5.200000, loss: 0.002704, epsilon: 0.010001, episode:  219\n",
      "frames: 417000, reward: -6.200000, loss: 0.000538, epsilon: 0.010001, episode:  220\n",
      "frames: 418000, reward: -6.200000, loss: 0.001073, epsilon: 0.010001, episode:  220\n",
      "frames: 419000, reward: -6.200000, loss: 0.001942, epsilon: 0.010001, episode:  220\n",
      "frames: 420000, reward: -6.200000, loss: 0.001616, epsilon: 0.010001, episode:  220\n",
      "frames: 421000, reward: -5.900000, loss: 0.000663, epsilon: 0.010001, episode:  221\n",
      "frames: 422000, reward: -5.900000, loss: 0.000891, epsilon: 0.010001, episode:  221\n",
      "frames: 423000, reward: -5.900000, loss: 0.001347, epsilon: 0.010001, episode:  221\n",
      "frames: 424000, reward: -5.900000, loss: 0.001237, epsilon: 0.010001, episode:  221\n",
      "frames: 425000, reward: -5.900000, loss: 0.000907, epsilon: 0.010001, episode:  221\n",
      "frames: 426000, reward: -5.400000, loss: 0.000853, epsilon: 0.010001, episode:  222\n",
      "frames: 427000, reward: -5.400000, loss: 0.001150, epsilon: 0.010001, episode:  222\n",
      "frames: 428000, reward: -5.400000, loss: 0.001282, epsilon: 0.010001, episode:  222\n",
      "frames: 429000, reward: -4.400000, loss: 0.000684, epsilon: 0.010001, episode:  223\n",
      "frames: 430000, reward: -4.400000, loss: 0.000766, epsilon: 0.010001, episode:  223\n",
      "frames: 431000, reward: -4.400000, loss: 0.000781, epsilon: 0.010001, episode:  223\n",
      "frames: 432000, reward: -4.400000, loss: 0.001529, epsilon: 0.010001, episode:  223\n",
      "frames: 433000, reward: -2.400000, loss: 0.000750, epsilon: 0.010001, episode:  224\n",
      "frames: 434000, reward: -2.400000, loss: 0.000472, epsilon: 0.010001, episode:  224\n",
      "frames: 435000, reward: -2.400000, loss: 0.002171, epsilon: 0.010000, episode:  224\n",
      "frames: 436000, reward: -0.200000, loss: 0.000528, epsilon: 0.010000, episode:  225\n",
      "frames: 437000, reward: -0.200000, loss: 0.000427, epsilon: 0.010000, episode:  225\n",
      "frames: 438000, reward: 1.700000, loss: 0.001134, epsilon: 0.010000, episode:  226\n",
      "frames: 439000, reward: 1.700000, loss: 0.000759, epsilon: 0.010000, episode:  226\n",
      "frames: 440000, reward: 3.300000, loss: 0.000654, epsilon: 0.010000, episode:  227\n",
      "frames: 441000, reward: 3.300000, loss: 0.000826, epsilon: 0.010000, episode:  227\n",
      "frames: 442000, reward: 3.300000, loss: 0.000871, epsilon: 0.010000, episode:  227\n",
      "frames: 443000, reward: 3.300000, loss: 0.000811, epsilon: 0.010000, episode:  227\n",
      "frames: 444000, reward: 3.800000, loss: 0.001604, epsilon: 0.010000, episode:  228\n",
      "frames: 445000, reward: 3.800000, loss: 0.000813, epsilon: 0.010000, episode:  228\n",
      "frames: 446000, reward: 3.800000, loss: 0.001893, epsilon: 0.010000, episode:  228\n",
      "frames: 447000, reward: 4.200000, loss: 0.000917, epsilon: 0.010000, episode:  229\n",
      "frames: 448000, reward: 4.200000, loss: 0.001214, epsilon: 0.010000, episode:  229\n",
      "frames: 449000, reward: 4.200000, loss: 0.001683, epsilon: 0.010000, episode:  229\n",
      "frames: 450000, reward: 6.600000, loss: 0.002106, epsilon: 0.010000, episode:  230\n",
      "frames: 451000, reward: 6.600000, loss: 0.000969, epsilon: 0.010000, episode:  230\n",
      "frames: 452000, reward: 8.200000, loss: 0.001150, epsilon: 0.010000, episode:  231\n",
      "frames: 453000, reward: 8.200000, loss: 0.000659, epsilon: 0.010000, episode:  231\n",
      "frames: 454000, reward: 8.200000, loss: 0.000375, epsilon: 0.010000, episode:  231\n",
      "frames: 455000, reward: 9.600000, loss: 0.002905, epsilon: 0.010000, episode:  232\n",
      "frames: 456000, reward: 9.600000, loss: 0.000458, epsilon: 0.010000, episode:  232\n",
      "frames: 457000, reward: 7.700000, loss: 0.001349, epsilon: 0.010000, episode:  233\n",
      "frames: 458000, reward: 7.700000, loss: 0.000675, epsilon: 0.010000, episode:  233\n",
      "frames: 459000, reward: 7.700000, loss: 0.003613, epsilon: 0.010000, episode:  233\n",
      "frames: 460000, reward: 7.500000, loss: 0.003374, epsilon: 0.010000, episode:  234\n",
      "frames: 461000, reward: 7.500000, loss: 0.000847, epsilon: 0.010000, episode:  234\n",
      "frames: 462000, reward: 7.500000, loss: 0.001809, epsilon: 0.010000, episode:  234\n",
      "frames: 463000, reward: 5.500000, loss: 0.000897, epsilon: 0.010000, episode:  235\n",
      "frames: 464000, reward: 5.500000, loss: 0.000848, epsilon: 0.010000, episode:  235\n",
      "frames: 465000, reward: 5.500000, loss: 0.001852, epsilon: 0.010000, episode:  235\n",
      "frames: 466000, reward: 5.500000, loss: 0.002175, epsilon: 0.010000, episode:  235\n",
      "frames: 467000, reward: 4.100000, loss: 0.000987, epsilon: 0.010000, episode:  236\n",
      "frames: 468000, reward: 4.100000, loss: 0.001283, epsilon: 0.010000, episode:  236\n",
      "frames: 469000, reward: 4.100000, loss: 0.000904, epsilon: 0.010000, episode:  236\n",
      "frames: 470000, reward: 3.300000, loss: 0.000773, epsilon: 0.010000, episode:  237\n",
      "frames: 471000, reward: 3.300000, loss: 0.000983, epsilon: 0.010000, episode:  237\n",
      "frames: 472000, reward: 3.300000, loss: 0.001775, epsilon: 0.010000, episode:  237\n",
      "frames: 473000, reward: 2.400000, loss: 0.001112, epsilon: 0.010000, episode:  238\n",
      "frames: 474000, reward: 2.400000, loss: 0.000900, epsilon: 0.010000, episode:  238\n",
      "frames: 475000, reward: 2.400000, loss: 0.001271, epsilon: 0.010000, episode:  238\n",
      "frames: 476000, reward: 2.400000, loss: 0.000741, epsilon: 0.010000, episode:  238\n",
      "frames: 477000, reward: 2.200000, loss: 0.000752, epsilon: 0.010000, episode:  239\n",
      "frames: 478000, reward: 2.200000, loss: 0.001277, epsilon: 0.010000, episode:  239\n",
      "frames: 479000, reward: 2.200000, loss: 0.000791, epsilon: 0.010000, episode:  239\n",
      "frames: 480000, reward: -0.100000, loss: 0.001248, epsilon: 0.010000, episode:  240\n",
      "frames: 481000, reward: -0.100000, loss: 0.000894, epsilon: 0.010000, episode:  240\n",
      "frames: 482000, reward: -0.100000, loss: 0.001448, epsilon: 0.010000, episode:  240\n",
      "frames: 483000, reward: -2.200000, loss: 0.001308, epsilon: 0.010000, episode:  241\n",
      "frames: 484000, reward: -2.200000, loss: 0.000830, epsilon: 0.010000, episode:  241\n",
      "frames: 485000, reward: -2.200000, loss: 0.000696, epsilon: 0.010000, episode:  241\n",
      "frames: 486000, reward: -2.200000, loss: 0.001069, epsilon: 0.010000, episode:  241\n",
      "frames: 487000, reward: -3.000000, loss: 0.001124, epsilon: 0.010000, episode:  242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 488000, reward: -3.000000, loss: 0.001846, epsilon: 0.010000, episode:  242\n",
      "frames: 489000, reward: -3.000000, loss: 0.000792, epsilon: 0.010000, episode:  242\n",
      "frames: 490000, reward: -0.900000, loss: 0.001174, epsilon: 0.010000, episode:  243\n",
      "frames: 491000, reward: -0.900000, loss: 0.001391, epsilon: 0.010000, episode:  243\n",
      "frames: 492000, reward: -0.900000, loss: 0.001016, epsilon: 0.010000, episode:  243\n",
      "frames: 493000, reward: -0.900000, loss: 0.000733, epsilon: 0.010000, episode:  243\n",
      "frames: 494000, reward: -1.300000, loss: 0.000499, epsilon: 0.010000, episode:  244\n",
      "frames: 495000, reward: -1.300000, loss: 0.001848, epsilon: 0.010000, episode:  244\n",
      "frames: 496000, reward: 1.100000, loss: 0.000708, epsilon: 0.010000, episode:  245\n",
      "frames: 497000, reward: 1.100000, loss: 0.004196, epsilon: 0.010000, episode:  245\n",
      "frames: 498000, reward: 1.100000, loss: 0.002113, epsilon: 0.010000, episode:  245\n",
      "frames: 499000, reward: 1.100000, loss: 0.000366, epsilon: 0.010000, episode:  245\n",
      "frames: 500000, reward: 1.100000, loss: 0.001324, epsilon: 0.010000, episode:  245\n",
      "frames: 501000, reward: 1.600000, loss: 0.001030, epsilon: 0.010000, episode:  246\n",
      "frames: 502000, reward: 1.600000, loss: 0.001956, epsilon: 0.010000, episode:  246\n",
      "frames: 503000, reward: 1.600000, loss: 0.001023, epsilon: 0.010000, episode:  246\n",
      "frames: 504000, reward: 0.400000, loss: 0.001001, epsilon: 0.010000, episode:  247\n",
      "frames: 505000, reward: 0.400000, loss: 0.000812, epsilon: 0.010000, episode:  247\n",
      "frames: 506000, reward: 0.400000, loss: 0.000344, epsilon: 0.010000, episode:  247\n",
      "frames: 507000, reward: 1.900000, loss: 0.000473, epsilon: 0.010000, episode:  248\n",
      "frames: 508000, reward: 1.900000, loss: 0.001298, epsilon: 0.010000, episode:  248\n",
      "frames: 509000, reward: 2.800000, loss: 0.000783, epsilon: 0.010000, episode:  249\n",
      "frames: 510000, reward: 2.800000, loss: 0.000720, epsilon: 0.010000, episode:  249\n",
      "frames: 511000, reward: 5.600000, loss: 0.000541, epsilon: 0.010000, episode:  250\n",
      "frames: 512000, reward: 5.600000, loss: 0.000956, epsilon: 0.010000, episode:  250\n",
      "frames: 513000, reward: 5.600000, loss: 0.001600, epsilon: 0.010000, episode:  250\n",
      "frames: 514000, reward: 6.600000, loss: 0.001685, epsilon: 0.010000, episode:  251\n",
      "frames: 515000, reward: 6.600000, loss: 0.001311, epsilon: 0.010000, episode:  251\n",
      "frames: 516000, reward: 6.600000, loss: 0.001319, epsilon: 0.010000, episode:  251\n",
      "frames: 517000, reward: 7.600000, loss: 0.000443, epsilon: 0.010000, episode:  252\n",
      "frames: 518000, reward: 7.600000, loss: 0.000719, epsilon: 0.010000, episode:  252\n",
      "frames: 519000, reward: 7.600000, loss: 0.000423, epsilon: 0.010000, episode:  252\n",
      "frames: 520000, reward: 8.000000, loss: 0.002873, epsilon: 0.010000, episode:  253\n",
      "frames: 521000, reward: 8.000000, loss: 0.001058, epsilon: 0.010000, episode:  253\n",
      "frames: 522000, reward: 9.600000, loss: 0.002520, epsilon: 0.010000, episode:  254\n",
      "frames: 523000, reward: 9.600000, loss: 0.000742, epsilon: 0.010000, episode:  254\n",
      "frames: 524000, reward: 6.700000, loss: 0.001469, epsilon: 0.010000, episode:  255\n",
      "frames: 525000, reward: 6.700000, loss: 0.000842, epsilon: 0.010000, episode:  255\n",
      "frames: 526000, reward: 6.700000, loss: 0.000762, epsilon: 0.010000, episode:  255\n",
      "frames: 527000, reward: 6.700000, loss: 0.001080, epsilon: 0.010000, episode:  255\n",
      "frames: 528000, reward: 6.500000, loss: 0.002383, epsilon: 0.010000, episode:  256\n",
      "frames: 529000, reward: 6.500000, loss: 0.000786, epsilon: 0.010000, episode:  256\n",
      "frames: 530000, reward: 8.400000, loss: 0.001097, epsilon: 0.010000, episode:  257\n",
      "frames: 531000, reward: 8.400000, loss: 0.000755, epsilon: 0.010000, episode:  257\n",
      "frames: 532000, reward: 8.400000, loss: 0.000700, epsilon: 0.010000, episode:  257\n",
      "frames: 533000, reward: 8.400000, loss: 0.000625, epsilon: 0.010000, episode:  257\n",
      "frames: 534000, reward: 7.400000, loss: 0.007146, epsilon: 0.010000, episode:  258\n",
      "frames: 535000, reward: 7.400000, loss: 0.000453, epsilon: 0.010000, episode:  258\n",
      "frames: 536000, reward: 7.400000, loss: 0.000838, epsilon: 0.010000, episode:  258\n",
      "frames: 537000, reward: 7.400000, loss: 0.002007, epsilon: 0.010000, episode:  258\n",
      "frames: 538000, reward: 6.700000, loss: 0.001997, epsilon: 0.010000, episode:  259\n",
      "frames: 539000, reward: 6.700000, loss: 0.000491, epsilon: 0.010000, episode:  259\n",
      "frames: 540000, reward: 6.400000, loss: 0.001276, epsilon: 0.010000, episode:  260\n",
      "frames: 541000, reward: 6.400000, loss: 0.001139, epsilon: 0.010000, episode:  260\n",
      "frames: 542000, reward: 6.400000, loss: 0.000783, epsilon: 0.010000, episode:  260\n",
      "frames: 543000, reward: 6.400000, loss: 0.001189, epsilon: 0.010000, episode:  260\n",
      "frames: 544000, reward: 5.500000, loss: 0.000833, epsilon: 0.010000, episode:  261\n",
      "frames: 545000, reward: 5.500000, loss: 0.000851, epsilon: 0.010000, episode:  261\n",
      "frames: 546000, reward: 5.500000, loss: 0.003746, epsilon: 0.010000, episode:  261\n",
      "frames: 547000, reward: 5.600000, loss: 0.000834, epsilon: 0.010000, episode:  262\n",
      "frames: 548000, reward: 5.600000, loss: 0.000984, epsilon: 0.010000, episode:  262\n",
      "frames: 549000, reward: 5.200000, loss: 0.006485, epsilon: 0.010000, episode:  263\n",
      "frames: 550000, reward: 5.200000, loss: 0.001200, epsilon: 0.010000, episode:  263\n",
      "frames: 551000, reward: 5.200000, loss: 0.001000, epsilon: 0.010000, episode:  263\n",
      "frames: 552000, reward: 5.200000, loss: 0.000470, epsilon: 0.010000, episode:  263\n",
      "frames: 553000, reward: 4.500000, loss: 0.000739, epsilon: 0.010000, episode:  264\n",
      "frames: 554000, reward: 4.500000, loss: 0.000932, epsilon: 0.010000, episode:  264\n",
      "frames: 555000, reward: 4.500000, loss: 0.000855, epsilon: 0.010000, episode:  264\n",
      "frames: 556000, reward: 6.900000, loss: 0.001622, epsilon: 0.010000, episode:  265\n",
      "frames: 557000, reward: 6.900000, loss: 0.000883, epsilon: 0.010000, episode:  265\n",
      "frames: 558000, reward: 8.300000, loss: 0.000388, epsilon: 0.010000, episode:  266\n",
      "frames: 559000, reward: 8.300000, loss: 0.000748, epsilon: 0.010000, episode:  266\n",
      "frames: 560000, reward: 9.000000, loss: 0.000795, epsilon: 0.010000, episode:  267\n",
      "frames: 561000, reward: 9.000000, loss: 0.000432, epsilon: 0.010000, episode:  267\n",
      "frames: 562000, reward: 9.000000, loss: 0.000566, epsilon: 0.010000, episode:  267\n",
      "frames: 563000, reward: 10.000000, loss: 0.000916, epsilon: 0.010000, episode:  268\n",
      "frames: 564000, reward: 10.000000, loss: 0.001890, epsilon: 0.010000, episode:  268\n",
      "frames: 565000, reward: 10.000000, loss: 0.000824, epsilon: 0.010000, episode:  268\n",
      "frames: 566000, reward: 10.100000, loss: 0.001145, epsilon: 0.010000, episode:  269\n",
      "frames: 567000, reward: 10.100000, loss: 0.000931, epsilon: 0.010000, episode:  269\n",
      "frames: 568000, reward: 10.100000, loss: 0.000885, epsilon: 0.010000, episode:  269\n",
      "frames: 569000, reward: 10.100000, loss: 0.001110, epsilon: 0.010000, episode:  269\n",
      "frames: 570000, reward: 8.900000, loss: 0.000807, epsilon: 0.010000, episode:  270\n",
      "frames: 571000, reward: 8.900000, loss: 0.000588, epsilon: 0.010000, episode:  270\n",
      "frames: 572000, reward: 8.900000, loss: 0.000740, epsilon: 0.010000, episode:  270\n",
      "frames: 573000, reward: 8.900000, loss: 0.001115, epsilon: 0.010000, episode:  270\n",
      "frames: 574000, reward: 10.200000, loss: 0.001425, epsilon: 0.010000, episode:  271\n",
      "frames: 575000, reward: 10.200000, loss: 0.000490, epsilon: 0.010000, episode:  271\n",
      "frames: 576000, reward: 10.400000, loss: 0.002086, epsilon: 0.010000, episode:  272\n",
      "frames: 577000, reward: 10.400000, loss: 0.001394, epsilon: 0.010000, episode:  272\n",
      "frames: 578000, reward: 10.400000, loss: 0.001012, epsilon: 0.010000, episode:  272\n",
      "frames: 579000, reward: 10.500000, loss: 0.000969, epsilon: 0.010000, episode:  273\n",
      "frames: 580000, reward: 10.500000, loss: 0.000984, epsilon: 0.010000, episode:  273\n",
      "frames: 581000, reward: 10.500000, loss: 0.001380, epsilon: 0.010000, episode:  273\n",
      "frames: 582000, reward: 10.500000, loss: 0.001373, epsilon: 0.010000, episode:  273\n",
      "frames: 583000, reward: 9.000000, loss: 0.001316, epsilon: 0.010000, episode:  274\n",
      "frames: 584000, reward: 9.000000, loss: 0.000459, epsilon: 0.010000, episode:  274\n",
      "frames: 585000, reward: 9.700000, loss: 0.000669, epsilon: 0.010000, episode:  275\n",
      "frames: 586000, reward: 9.700000, loss: 0.000664, epsilon: 0.010000, episode:  275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 587000, reward: 9.600000, loss: 0.000497, epsilon: 0.010000, episode:  276\n",
      "frames: 588000, reward: 9.600000, loss: 0.000564, epsilon: 0.010000, episode:  276\n",
      "frames: 589000, reward: 9.600000, loss: 0.000488, epsilon: 0.010000, episode:  277\n",
      "frames: 590000, reward: 9.600000, loss: 0.000654, epsilon: 0.010000, episode:  277\n",
      "frames: 591000, reward: 10.500000, loss: 0.000423, epsilon: 0.010000, episode:  278\n",
      "frames: 592000, reward: 10.500000, loss: 0.000289, epsilon: 0.010000, episode:  278\n",
      "frames: 593000, reward: 10.500000, loss: 0.000554, epsilon: 0.010000, episode:  278\n",
      "frames: 594000, reward: 11.400000, loss: 0.000429, epsilon: 0.010000, episode:  279\n",
      "frames: 595000, reward: 11.400000, loss: 0.001254, epsilon: 0.010000, episode:  279\n",
      "frames: 596000, reward: 11.400000, loss: 0.003493, epsilon: 0.010000, episode:  279\n",
      "frames: 597000, reward: 12.300000, loss: 0.000410, epsilon: 0.010000, episode:  280\n",
      "frames: 598000, reward: 12.300000, loss: 0.002243, epsilon: 0.010000, episode:  280\n",
      "frames: 599000, reward: 13.300000, loss: 0.002516, epsilon: 0.010000, episode:  281\n",
      "frames: 600000, reward: 13.300000, loss: 0.000498, epsilon: 0.010000, episode:  281\n",
      "frames: 601000, reward: 13.300000, loss: 0.000259, epsilon: 0.010000, episode:  282\n",
      "frames: 602000, reward: 13.300000, loss: 0.000458, epsilon: 0.010000, episode:  282\n",
      "frames: 603000, reward: 13.900000, loss: 0.000213, epsilon: 0.010000, episode:  283\n",
      "frames: 604000, reward: 13.900000, loss: 0.000517, epsilon: 0.010000, episode:  283\n",
      "frames: 605000, reward: 13.900000, loss: 0.000449, epsilon: 0.010000, episode:  283\n",
      "frames: 606000, reward: 13.900000, loss: 0.000946, epsilon: 0.010000, episode:  283\n",
      "frames: 607000, reward: 14.300000, loss: 0.000583, epsilon: 0.010000, episode:  284\n",
      "frames: 608000, reward: 14.300000, loss: 0.000569, epsilon: 0.010000, episode:  284\n",
      "frames: 609000, reward: 14.300000, loss: 0.000895, epsilon: 0.010000, episode:  284\n",
      "frames: 610000, reward: 13.600000, loss: 0.000647, epsilon: 0.010000, episode:  285\n",
      "frames: 611000, reward: 13.600000, loss: 0.000751, epsilon: 0.010000, episode:  285\n",
      "frames: 612000, reward: 13.600000, loss: 0.001143, epsilon: 0.010000, episode:  285\n",
      "frames: 613000, reward: 12.300000, loss: 0.000751, epsilon: 0.010000, episode:  286\n",
      "frames: 614000, reward: 12.300000, loss: 0.001152, epsilon: 0.010000, episode:  286\n",
      "frames: 615000, reward: 12.300000, loss: 0.001670, epsilon: 0.010000, episode:  286\n",
      "frames: 616000, reward: 11.500000, loss: 0.001252, epsilon: 0.010000, episode:  287\n",
      "frames: 617000, reward: 11.500000, loss: 0.001245, epsilon: 0.010000, episode:  287\n",
      "frames: 618000, reward: 11.500000, loss: 0.000447, epsilon: 0.010000, episode:  287\n",
      "frames: 619000, reward: 11.500000, loss: 0.000829, epsilon: 0.010000, episode:  287\n",
      "frames: 620000, reward: 9.200000, loss: 0.000701, epsilon: 0.010000, episode:  288\n",
      "frames: 621000, reward: 9.200000, loss: 0.000583, epsilon: 0.010000, episode:  288\n",
      "frames: 622000, reward: 9.000000, loss: 0.000428, epsilon: 0.010000, episode:  289\n",
      "frames: 623000, reward: 9.000000, loss: 0.001153, epsilon: 0.010000, episode:  289\n",
      "frames: 624000, reward: 9.000000, loss: 0.010249, epsilon: 0.010000, episode:  289\n",
      "frames: 625000, reward: 8.000000, loss: 0.002343, epsilon: 0.010000, episode:  290\n",
      "frames: 626000, reward: 8.000000, loss: 0.001148, epsilon: 0.010000, episode:  290\n",
      "frames: 627000, reward: 8.000000, loss: 0.000514, epsilon: 0.010000, episode:  290\n",
      "frames: 628000, reward: 7.600000, loss: 0.000320, epsilon: 0.010000, episode:  291\n",
      "frames: 629000, reward: 8.300000, loss: 0.000535, epsilon: 0.010000, episode:  292\n",
      "frames: 630000, reward: 8.300000, loss: 0.000780, epsilon: 0.010000, episode:  292\n",
      "frames: 631000, reward: 8.300000, loss: 0.000606, epsilon: 0.010000, episode:  292\n",
      "frames: 632000, reward: 8.200000, loss: 0.000747, epsilon: 0.010000, episode:  293\n",
      "frames: 633000, reward: 8.200000, loss: 0.000408, epsilon: 0.010000, episode:  293\n",
      "frames: 634000, reward: 9.900000, loss: 0.000647, epsilon: 0.010000, episode:  294\n",
      "frames: 635000, reward: 9.900000, loss: 0.000446, epsilon: 0.010000, episode:  294\n",
      "frames: 636000, reward: 9.900000, loss: 0.000878, epsilon: 0.010000, episode:  294\n",
      "frames: 637000, reward: 9.900000, loss: 0.000567, epsilon: 0.010000, episode:  294\n",
      "frames: 638000, reward: 9.600000, loss: 0.000723, epsilon: 0.010000, episode:  295\n",
      "frames: 639000, reward: 9.600000, loss: 0.000402, epsilon: 0.010000, episode:  295\n",
      "frames: 640000, reward: 9.600000, loss: 0.001206, epsilon: 0.010000, episode:  295\n",
      "frames: 641000, reward: 9.900000, loss: 0.000615, epsilon: 0.010000, episode:  296\n",
      "frames: 642000, reward: 9.900000, loss: 0.000549, epsilon: 0.010000, episode:  296\n",
      "frames: 643000, reward: 9.900000, loss: 0.000496, epsilon: 0.010000, episode:  296\n",
      "frames: 644000, reward: 9.600000, loss: 0.000932, epsilon: 0.010000, episode:  297\n",
      "frames: 645000, reward: 9.600000, loss: 0.000967, epsilon: 0.010000, episode:  297\n",
      "frames: 646000, reward: 11.300000, loss: 0.001190, epsilon: 0.010000, episode:  298\n",
      "frames: 647000, reward: 11.300000, loss: 0.000585, epsilon: 0.010000, episode:  298\n",
      "frames: 648000, reward: 11.900000, loss: 0.000306, epsilon: 0.010000, episode:  299\n",
      "frames: 649000, reward: 11.900000, loss: 0.000364, epsilon: 0.010000, episode:  299\n",
      "frames: 650000, reward: 13.500000, loss: 0.000352, epsilon: 0.010000, episode:  300\n",
      "frames: 651000, reward: 13.500000, loss: 0.000394, epsilon: 0.010000, episode:  300\n",
      "frames: 652000, reward: 13.800000, loss: 0.000375, epsilon: 0.010000, episode:  301\n",
      "frames: 653000, reward: 13.800000, loss: 0.000318, epsilon: 0.010000, episode:  301\n",
      "frames: 654000, reward: 13.800000, loss: 0.000709, epsilon: 0.010000, episode:  301\n",
      "frames: 655000, reward: 13.000000, loss: 0.000404, epsilon: 0.010000, episode:  302\n",
      "frames: 656000, reward: 13.000000, loss: 0.000302, epsilon: 0.010000, episode:  302\n",
      "frames: 657000, reward: 13.000000, loss: 0.000260, epsilon: 0.010000, episode:  302\n",
      "frames: 658000, reward: 12.800000, loss: 0.000497, epsilon: 0.010000, episode:  303\n",
      "frames: 659000, reward: 13.000000, loss: 0.000252, epsilon: 0.010000, episode:  304\n",
      "frames: 660000, reward: 13.000000, loss: 0.000520, epsilon: 0.010000, episode:  304\n",
      "frames: 661000, reward: 13.000000, loss: 0.000566, epsilon: 0.010000, episode:  304\n",
      "frames: 662000, reward: 13.000000, loss: 0.001263, epsilon: 0.010000, episode:  304\n",
      "frames: 663000, reward: 12.800000, loss: 0.000314, epsilon: 0.010000, episode:  305\n",
      "frames: 664000, reward: 14.200000, loss: 0.000383, epsilon: 0.010000, episode:  306\n",
      "frames: 665000, reward: 14.200000, loss: 0.000651, epsilon: 0.010000, episode:  306\n",
      "frames: 666000, reward: 14.200000, loss: 0.000517, epsilon: 0.010000, episode:  306\n",
      "frames: 667000, reward: 14.300000, loss: 0.000387, epsilon: 0.010000, episode:  307\n",
      "frames: 668000, reward: 14.300000, loss: 0.000609, epsilon: 0.010000, episode:  307\n",
      "frames: 669000, reward: 14.300000, loss: 0.001253, epsilon: 0.010000, episode:  307\n",
      "frames: 670000, reward: 14.900000, loss: 0.000976, epsilon: 0.010000, episode:  308\n",
      "frames: 671000, reward: 14.900000, loss: 0.000865, epsilon: 0.010000, episode:  308\n",
      "frames: 672000, reward: 14.400000, loss: 0.001743, epsilon: 0.010000, episode:  309\n",
      "frames: 673000, reward: 14.400000, loss: 0.000432, epsilon: 0.010000, episode:  309\n",
      "frames: 674000, reward: 14.100000, loss: 0.001640, epsilon: 0.010000, episode:  310\n",
      "frames: 675000, reward: 14.100000, loss: 0.000628, epsilon: 0.010000, episode:  310\n",
      "frames: 676000, reward: 14.100000, loss: 0.001321, epsilon: 0.010000, episode:  310\n",
      "frames: 677000, reward: 13.700000, loss: 0.001226, epsilon: 0.010000, episode:  311\n",
      "frames: 678000, reward: 13.700000, loss: 0.000548, epsilon: 0.010000, episode:  311\n",
      "frames: 679000, reward: 13.700000, loss: 0.000864, epsilon: 0.010000, episode:  311\n",
      "frames: 680000, reward: 13.500000, loss: 0.000417, epsilon: 0.010000, episode:  312\n",
      "frames: 681000, reward: 13.500000, loss: 0.000348, epsilon: 0.010000, episode:  312\n",
      "frames: 682000, reward: 13.400000, loss: 0.000663, epsilon: 0.010000, episode:  313\n",
      "frames: 683000, reward: 13.400000, loss: 0.000768, epsilon: 0.010000, episode:  313\n",
      "frames: 684000, reward: 13.400000, loss: 0.001426, epsilon: 0.010000, episode:  313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 685000, reward: 12.300000, loss: 0.000731, epsilon: 0.010000, episode:  314\n",
      "frames: 686000, reward: 12.300000, loss: 0.000712, epsilon: 0.010000, episode:  314\n",
      "frames: 687000, reward: 12.300000, loss: 0.001138, epsilon: 0.010000, episode:  314\n",
      "frames: 688000, reward: 12.700000, loss: 0.000966, epsilon: 0.010000, episode:  315\n",
      "frames: 689000, reward: 12.700000, loss: 0.001151, epsilon: 0.010000, episode:  315\n",
      "frames: 690000, reward: 12.700000, loss: 0.000668, epsilon: 0.010000, episode:  315\n",
      "frames: 691000, reward: 12.700000, loss: 0.000705, epsilon: 0.010000, episode:  315\n",
      "frames: 692000, reward: 10.900000, loss: 0.000718, epsilon: 0.010000, episode:  316\n",
      "frames: 693000, reward: 10.900000, loss: 0.000551, epsilon: 0.010000, episode:  316\n",
      "frames: 694000, reward: 11.500000, loss: 0.001113, epsilon: 0.010000, episode:  317\n",
      "frames: 695000, reward: 11.500000, loss: 0.000728, epsilon: 0.010000, episode:  317\n",
      "frames: 696000, reward: 11.500000, loss: 0.000831, epsilon: 0.010000, episode:  317\n",
      "frames: 697000, reward: 11.100000, loss: 0.000841, epsilon: 0.010000, episode:  318\n",
      "frames: 698000, reward: 11.100000, loss: 0.000806, epsilon: 0.010000, episode:  318\n",
      "frames: 699000, reward: 11.100000, loss: 0.018193, epsilon: 0.010000, episode:  318\n",
      "frames: 700000, reward: 11.000000, loss: 0.000514, epsilon: 0.010000, episode:  319\n",
      "frames: 701000, reward: 11.000000, loss: 0.000540, epsilon: 0.010000, episode:  319\n",
      "frames: 702000, reward: 11.000000, loss: 0.001036, epsilon: 0.010000, episode:  319\n",
      "frames: 703000, reward: 9.800000, loss: 0.000714, epsilon: 0.010000, episode:  320\n",
      "frames: 704000, reward: 9.800000, loss: 0.000566, epsilon: 0.010000, episode:  320\n",
      "frames: 705000, reward: 9.800000, loss: 0.000538, epsilon: 0.010000, episode:  320\n",
      "frames: 706000, reward: 10.200000, loss: 0.001101, epsilon: 0.010000, episode:  321\n",
      "frames: 707000, reward: 10.200000, loss: 0.000461, epsilon: 0.010000, episode:  321\n",
      "frames: 708000, reward: 10.900000, loss: 0.000426, epsilon: 0.010000, episode:  322\n",
      "frames: 709000, reward: 10.900000, loss: 0.000520, epsilon: 0.010000, episode:  322\n",
      "frames: 710000, reward: 10.900000, loss: 0.000462, epsilon: 0.010000, episode:  322\n",
      "frames: 711000, reward: 11.200000, loss: 0.000812, epsilon: 0.010000, episode:  323\n",
      "frames: 712000, reward: 11.200000, loss: 0.000379, epsilon: 0.010000, episode:  323\n",
      "frames: 713000, reward: 11.700000, loss: 0.000600, epsilon: 0.010000, episode:  324\n",
      "frames: 714000, reward: 11.700000, loss: 0.000431, epsilon: 0.010000, episode:  324\n",
      "frames: 715000, reward: 12.700000, loss: 0.000140, epsilon: 0.010000, episode:  325\n",
      "frames: 716000, reward: 12.700000, loss: 0.000800, epsilon: 0.010000, episode:  325\n",
      "frames: 717000, reward: 12.700000, loss: 0.001397, epsilon: 0.010000, episode:  325\n",
      "frames: 718000, reward: 13.100000, loss: 0.000669, epsilon: 0.010000, episode:  326\n",
      "frames: 719000, reward: 13.100000, loss: 0.000640, epsilon: 0.010000, episode:  326\n",
      "frames: 720000, reward: 13.100000, loss: 0.000367, epsilon: 0.010000, episode:  326\n",
      "frames: 721000, reward: 13.100000, loss: 0.000689, epsilon: 0.010000, episode:  327\n",
      "frames: 722000, reward: 13.100000, loss: 0.000502, epsilon: 0.010000, episode:  327\n",
      "frames: 723000, reward: 13.100000, loss: 0.002643, epsilon: 0.010000, episode:  327\n",
      "frames: 724000, reward: 12.600000, loss: 0.001262, epsilon: 0.010000, episode:  328\n",
      "frames: 725000, reward: 12.600000, loss: 0.000747, epsilon: 0.010000, episode:  328\n",
      "frames: 726000, reward: 12.000000, loss: 0.002054, epsilon: 0.010000, episode:  329\n",
      "frames: 727000, reward: 12.000000, loss: 0.005590, epsilon: 0.010000, episode:  329\n",
      "frames: 728000, reward: 12.000000, loss: 0.000612, epsilon: 0.010000, episode:  329\n",
      "frames: 729000, reward: 13.500000, loss: 0.000892, epsilon: 0.010000, episode:  330\n",
      "frames: 730000, reward: 13.500000, loss: 0.000394, epsilon: 0.010000, episode:  330\n",
      "frames: 731000, reward: 13.300000, loss: 0.001842, epsilon: 0.010000, episode:  331\n",
      "frames: 732000, reward: 13.300000, loss: 0.000703, epsilon: 0.010000, episode:  331\n",
      "frames: 733000, reward: 13.100000, loss: 0.001070, epsilon: 0.010000, episode:  332\n",
      "frames: 734000, reward: 13.100000, loss: 0.000534, epsilon: 0.010000, episode:  332\n",
      "frames: 735000, reward: 13.100000, loss: 0.000431, epsilon: 0.010000, episode:  332\n",
      "frames: 736000, reward: 12.900000, loss: 0.000324, epsilon: 0.010000, episode:  333\n",
      "frames: 737000, reward: 12.900000, loss: 0.000498, epsilon: 0.010000, episode:  333\n",
      "frames: 738000, reward: 13.200000, loss: 0.000756, epsilon: 0.010000, episode:  334\n",
      "frames: 739000, reward: 13.200000, loss: 0.000452, epsilon: 0.010000, episode:  334\n",
      "frames: 740000, reward: 12.900000, loss: 0.000364, epsilon: 0.010000, episode:  335\n",
      "frames: 741000, reward: 12.900000, loss: 0.000263, epsilon: 0.010000, episode:  335\n",
      "frames: 742000, reward: 14.300000, loss: 0.000377, epsilon: 0.010000, episode:  336\n",
      "frames: 743000, reward: 14.300000, loss: 0.001223, epsilon: 0.010000, episode:  336\n",
      "frames: 744000, reward: 14.800000, loss: 0.000346, epsilon: 0.010000, episode:  337\n",
      "frames: 745000, reward: 14.800000, loss: 0.001508, epsilon: 0.010000, episode:  337\n",
      "frames: 746000, reward: 15.500000, loss: 0.000409, epsilon: 0.010000, episode:  338\n",
      "frames: 747000, reward: 15.500000, loss: 0.000423, epsilon: 0.010000, episode:  338\n",
      "frames: 748000, reward: 16.000000, loss: 0.000315, epsilon: 0.010000, episode:  339\n",
      "frames: 749000, reward: 16.000000, loss: 0.000235, epsilon: 0.010000, episode:  339\n",
      "frames: 750000, reward: 16.100000, loss: 0.000253, epsilon: 0.010000, episode:  340\n",
      "frames: 751000, reward: 16.100000, loss: 0.000441, epsilon: 0.010000, episode:  340\n",
      "frames: 752000, reward: 16.700000, loss: 0.000541, epsilon: 0.010000, episode:  341\n",
      "frames: 753000, reward: 16.700000, loss: 0.000644, epsilon: 0.010000, episode:  341\n",
      "frames: 754000, reward: 17.100000, loss: 0.000445, epsilon: 0.010000, episode:  342\n",
      "frames: 755000, reward: 17.100000, loss: 0.000526, epsilon: 0.010000, episode:  342\n",
      "frames: 756000, reward: 17.600000, loss: 0.000887, epsilon: 0.010000, episode:  343\n",
      "frames: 757000, reward: 17.600000, loss: 0.000272, epsilon: 0.010000, episode:  343\n",
      "frames: 758000, reward: 17.600000, loss: 0.000838, epsilon: 0.010000, episode:  344\n",
      "frames: 759000, reward: 17.600000, loss: 0.001809, epsilon: 0.010000, episode:  344\n",
      "frames: 760000, reward: 18.100000, loss: 0.000309, epsilon: 0.010000, episode:  345\n",
      "frames: 761000, reward: 18.100000, loss: 0.000215, epsilon: 0.010000, episode:  345\n",
      "frames: 762000, reward: 18.100000, loss: 0.000162, epsilon: 0.010000, episode:  346\n",
      "frames: 763000, reward: 18.100000, loss: 0.000154, epsilon: 0.010000, episode:  346\n",
      "frames: 764000, reward: 18.200000, loss: 0.000822, epsilon: 0.010000, episode:  347\n",
      "frames: 765000, reward: 18.200000, loss: 0.000376, epsilon: 0.010000, episode:  347\n",
      "frames: 766000, reward: 18.300000, loss: 0.000433, epsilon: 0.010000, episode:  348\n",
      "frames: 767000, reward: 18.300000, loss: 0.000202, epsilon: 0.010000, episode:  348\n",
      "frames: 768000, reward: 19.000000, loss: 0.000172, epsilon: 0.010000, episode:  349\n",
      "frames: 769000, reward: 19.300000, loss: 0.000133, epsilon: 0.010000, episode:  350\n",
      "frames: 770000, reward: 19.300000, loss: 0.000169, epsilon: 0.010000, episode:  350\n",
      "frames: 771000, reward: 19.300000, loss: 0.000288, epsilon: 0.010000, episode:  351\n",
      "frames: 772000, reward: 19.300000, loss: 0.000092, epsilon: 0.010000, episode:  351\n",
      "frames: 773000, reward: 18.900000, loss: 0.000320, epsilon: 0.010000, episode:  352\n",
      "frames: 774000, reward: 18.900000, loss: 0.000316, epsilon: 0.010000, episode:  352\n",
      "frames: 775000, reward: 19.300000, loss: 0.000129, epsilon: 0.010000, episode:  353\n",
      "frames: 776000, reward: 19.300000, loss: 0.000209, epsilon: 0.010000, episode:  353\n",
      "frames: 777000, reward: 19.700000, loss: 0.000142, epsilon: 0.010000, episode:  354\n",
      "frames: 778000, reward: 19.800000, loss: 0.000820, epsilon: 0.010000, episode:  355\n",
      "frames: 779000, reward: 19.800000, loss: 0.000273, epsilon: 0.010000, episode:  355\n",
      "frames: 780000, reward: 19.800000, loss: 0.000203, epsilon: 0.010000, episode:  356\n",
      "frames: 781000, reward: 19.800000, loss: 0.000155, epsilon: 0.010000, episode:  356\n",
      "frames: 782000, reward: 19.600000, loss: 0.000195, epsilon: 0.010000, episode:  357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 783000, reward: 19.600000, loss: 0.000302, epsilon: 0.010000, episode:  357\n",
      "frames: 784000, reward: 20.000000, loss: 0.000139, epsilon: 0.010000, episode:  358\n",
      "frames: 785000, reward: 20.000000, loss: 0.000263, epsilon: 0.010000, episode:  358\n",
      "frames: 786000, reward: 19.900000, loss: 0.000211, epsilon: 0.010000, episode:  359\n",
      "frames: 787000, reward: 19.900000, loss: 0.000244, epsilon: 0.010000, episode:  359\n",
      "frames: 788000, reward: 19.500000, loss: 0.000102, epsilon: 0.010000, episode:  360\n",
      "frames: 789000, reward: 19.600000, loss: 0.000113, epsilon: 0.010000, episode:  361\n",
      "frames: 790000, reward: 19.600000, loss: 0.000204, epsilon: 0.010000, episode:  361\n",
      "frames: 791000, reward: 20.100000, loss: 0.000105, epsilon: 0.010000, episode:  362\n",
      "frames: 792000, reward: 20.100000, loss: 0.000120, epsilon: 0.010000, episode:  362\n",
      "frames: 793000, reward: 20.000000, loss: 0.000944, epsilon: 0.010000, episode:  363\n",
      "frames: 794000, reward: 20.000000, loss: 0.000075, epsilon: 0.010000, episode:  364\n",
      "frames: 795000, reward: 20.000000, loss: 0.000247, epsilon: 0.010000, episode:  364\n",
      "frames: 796000, reward: 20.000000, loss: 0.000250, epsilon: 0.010000, episode:  365\n",
      "frames: 797000, reward: 20.000000, loss: 0.000164, epsilon: 0.010000, episode:  365\n",
      "frames: 798000, reward: 19.900000, loss: 0.000623, epsilon: 0.010000, episode:  366\n",
      "frames: 799000, reward: 19.900000, loss: 0.000153, epsilon: 0.010000, episode:  366\n",
      "frames: 800000, reward: 20.200000, loss: 0.000064, epsilon: 0.010000, episode:  367\n",
      "frames: 801000, reward: 20.200000, loss: 0.000249, epsilon: 0.010000, episode:  367\n",
      "frames: 802000, reward: 20.000000, loss: 0.000130, epsilon: 0.010000, episode:  368\n",
      "frames: 803000, reward: 20.000000, loss: 0.000233, epsilon: 0.010000, episode:  368\n",
      "frames: 804000, reward: 19.800000, loss: 0.000208, epsilon: 0.010000, episode:  369\n",
      "frames: 805000, reward: 20.200000, loss: 0.000412, epsilon: 0.010000, episode:  370\n",
      "frames: 806000, reward: 20.200000, loss: 0.000062, epsilon: 0.010000, episode:  370\n",
      "frames: 807000, reward: 20.100000, loss: 0.000110, epsilon: 0.010000, episode:  371\n",
      "frames: 808000, reward: 20.100000, loss: 0.000133, epsilon: 0.010000, episode:  371\n",
      "frames: 809000, reward: 20.000000, loss: 0.000166, epsilon: 0.010000, episode:  372\n",
      "frames: 810000, reward: 20.000000, loss: 0.000095, epsilon: 0.010000, episode:  373\n",
      "frames: 811000, reward: 20.000000, loss: 0.000165, epsilon: 0.010000, episode:  373\n",
      "frames: 812000, reward: 20.000000, loss: 0.000300, epsilon: 0.010000, episode:  374\n",
      "frames: 813000, reward: 20.000000, loss: 0.000452, epsilon: 0.010000, episode:  374\n",
      "frames: 814000, reward: 19.900000, loss: 0.000147, epsilon: 0.010000, episode:  375\n",
      "frames: 815000, reward: 19.900000, loss: 0.000170, epsilon: 0.010000, episode:  375\n",
      "frames: 816000, reward: 19.500000, loss: 0.001567, epsilon: 0.010000, episode:  376\n",
      "frames: 817000, reward: 19.500000, loss: 0.000330, epsilon: 0.010000, episode:  376\n",
      "frames: 818000, reward: 19.400000, loss: 0.000129, epsilon: 0.010000, episode:  377\n",
      "frames: 819000, reward: 19.400000, loss: 0.001731, epsilon: 0.010000, episode:  377\n",
      "frames: 820000, reward: 19.400000, loss: 0.001374, epsilon: 0.010000, episode:  378\n",
      "frames: 821000, reward: 19.400000, loss: 0.000244, epsilon: 0.010000, episode:  378\n",
      "frames: 822000, reward: 19.300000, loss: 0.000590, epsilon: 0.010000, episode:  379\n",
      "frames: 823000, reward: 19.300000, loss: 0.000136, epsilon: 0.010000, episode:  379\n",
      "frames: 824000, reward: 19.100000, loss: 0.000276, epsilon: 0.010000, episode:  380\n",
      "frames: 825000, reward: 19.100000, loss: 0.000218, epsilon: 0.010000, episode:  380\n",
      "frames: 826000, reward: 18.900000, loss: 0.000448, epsilon: 0.010000, episode:  381\n",
      "frames: 827000, reward: 18.900000, loss: 0.000108, epsilon: 0.010000, episode:  381\n",
      "frames: 828000, reward: 19.000000, loss: 0.000368, epsilon: 0.010000, episode:  382\n",
      "frames: 829000, reward: 19.000000, loss: 0.000130, epsilon: 0.010000, episode:  383\n",
      "frames: 830000, reward: 19.000000, loss: 0.000148, epsilon: 0.010000, episode:  383\n",
      "frames: 831000, reward: 18.900000, loss: 0.000096, epsilon: 0.010000, episode:  384\n",
      "frames: 832000, reward: 18.900000, loss: 0.000042, epsilon: 0.010000, episode:  384\n",
      "frames: 833000, reward: 18.800000, loss: 0.000225, epsilon: 0.010000, episode:  385\n",
      "frames: 834000, reward: 18.800000, loss: 0.000195, epsilon: 0.010000, episode:  385\n",
      "frames: 835000, reward: 19.000000, loss: 0.000238, epsilon: 0.010000, episode:  386\n",
      "frames: 836000, reward: 19.100000, loss: 0.000115, epsilon: 0.010000, episode:  387\n",
      "frames: 837000, reward: 19.100000, loss: 0.000079, epsilon: 0.010000, episode:  387\n",
      "frames: 838000, reward: 19.400000, loss: 0.000170, epsilon: 0.010000, episode:  388\n",
      "frames: 839000, reward: 19.400000, loss: 0.000153, epsilon: 0.010000, episode:  388\n",
      "frames: 840000, reward: 19.800000, loss: 0.000190, epsilon: 0.010000, episode:  389\n",
      "frames: 841000, reward: 19.800000, loss: 0.002070, epsilon: 0.010000, episode:  389\n",
      "frames: 842000, reward: 19.700000, loss: 0.000213, epsilon: 0.010000, episode:  390\n",
      "frames: 843000, reward: 20.000000, loss: 0.000184, epsilon: 0.010000, episode:  391\n",
      "frames: 844000, reward: 20.000000, loss: 0.000176, epsilon: 0.010000, episode:  391\n",
      "frames: 845000, reward: 19.700000, loss: 0.000104, epsilon: 0.010000, episode:  392\n",
      "frames: 846000, reward: 19.700000, loss: 0.000118, epsilon: 0.010000, episode:  392\n",
      "frames: 847000, reward: 19.700000, loss: 0.000145, epsilon: 0.010000, episode:  393\n",
      "frames: 848000, reward: 19.700000, loss: 0.000269, epsilon: 0.010000, episode:  393\n",
      "frames: 849000, reward: 19.800000, loss: 0.000225, epsilon: 0.010000, episode:  394\n",
      "frames: 850000, reward: 20.000000, loss: 0.000078, epsilon: 0.010000, episode:  395\n",
      "frames: 851000, reward: 20.000000, loss: 0.000134, epsilon: 0.010000, episode:  395\n",
      "frames: 852000, reward: 20.200000, loss: 0.000500, epsilon: 0.010000, episode:  396\n",
      "frames: 853000, reward: 20.200000, loss: 0.000260, epsilon: 0.010000, episode:  396\n",
      "frames: 854000, reward: 20.100000, loss: 0.000171, epsilon: 0.010000, episode:  397\n",
      "frames: 855000, reward: 20.100000, loss: 0.000124, epsilon: 0.010000, episode:  397\n",
      "frames: 856000, reward: 19.900000, loss: 0.000129, epsilon: 0.010000, episode:  398\n",
      "frames: 857000, reward: 19.900000, loss: 0.000061, epsilon: 0.010000, episode:  398\n",
      "frames: 858000, reward: 19.700000, loss: 0.000150, epsilon: 0.010000, episode:  399\n",
      "frames: 859000, reward: 19.700000, loss: 0.000144, epsilon: 0.010000, episode:  399\n",
      "frames: 860000, reward: 20.000000, loss: 0.000118, epsilon: 0.010000, episode:  400\n",
      "frames: 861000, reward: 20.000000, loss: 0.000275, epsilon: 0.010000, episode:  401\n",
      "frames: 862000, reward: 20.000000, loss: 0.000103, epsilon: 0.010000, episode:  401\n",
      "frames: 863000, reward: 20.200000, loss: 0.000245, epsilon: 0.010000, episode:  402\n",
      "frames: 864000, reward: 20.200000, loss: 0.000130, epsilon: 0.010000, episode:  402\n",
      "frames: 865000, reward: 20.000000, loss: 0.000214, epsilon: 0.010000, episode:  403\n",
      "frames: 866000, reward: 20.000000, loss: 0.000196, epsilon: 0.010000, episode:  403\n",
      "frames: 867000, reward: 19.800000, loss: 0.000242, epsilon: 0.010000, episode:  404\n",
      "frames: 868000, reward: 19.800000, loss: 0.000149, epsilon: 0.010000, episode:  404\n",
      "frames: 869000, reward: 19.600000, loss: 0.000462, epsilon: 0.010000, episode:  405\n",
      "frames: 870000, reward: 19.600000, loss: 0.000107, epsilon: 0.010000, episode:  405\n",
      "frames: 871000, reward: 19.600000, loss: 0.000216, epsilon: 0.010000, episode:  406\n",
      "frames: 872000, reward: 19.600000, loss: 0.000183, epsilon: 0.010000, episode:  406\n",
      "frames: 873000, reward: 19.600000, loss: 0.000135, epsilon: 0.010000, episode:  407\n",
      "frames: 874000, reward: 19.600000, loss: 0.000093, epsilon: 0.010000, episode:  407\n",
      "frames: 875000, reward: 19.600000, loss: 0.000084, epsilon: 0.010000, episode:  408\n",
      "frames: 876000, reward: 19.600000, loss: 0.000210, epsilon: 0.010000, episode:  408\n",
      "frames: 877000, reward: 19.700000, loss: 0.000158, epsilon: 0.010000, episode:  409\n",
      "frames: 878000, reward: 19.700000, loss: 0.000096, epsilon: 0.010000, episode:  409\n",
      "frames: 879000, reward: 19.400000, loss: 0.000326, epsilon: 0.010000, episode:  410\n",
      "frames: 880000, reward: 19.300000, loss: 0.000153, epsilon: 0.010000, episode:  411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 881000, reward: 19.300000, loss: 0.000086, epsilon: 0.010000, episode:  411\n",
      "frames: 882000, reward: 19.300000, loss: 0.000118, epsilon: 0.010000, episode:  411\n",
      "frames: 883000, reward: 18.700000, loss: 0.000292, epsilon: 0.010000, episode:  412\n",
      "frames: 884000, reward: 18.700000, loss: 0.000310, epsilon: 0.010000, episode:  412\n",
      "frames: 885000, reward: 18.600000, loss: 0.000363, epsilon: 0.010000, episode:  413\n",
      "frames: 886000, reward: 18.600000, loss: 0.000259, epsilon: 0.010000, episode:  413\n",
      "frames: 887000, reward: 18.800000, loss: 0.000214, epsilon: 0.010000, episode:  414\n",
      "frames: 888000, reward: 19.000000, loss: 0.000150, epsilon: 0.010000, episode:  415\n",
      "frames: 889000, reward: 19.000000, loss: 0.000230, epsilon: 0.010000, episode:  415\n",
      "frames: 890000, reward: 19.000000, loss: 0.000221, epsilon: 0.010000, episode:  416\n",
      "frames: 891000, reward: 19.000000, loss: 0.000186, epsilon: 0.010000, episode:  416\n",
      "frames: 892000, reward: 18.900000, loss: 0.000283, epsilon: 0.010000, episode:  417\n",
      "frames: 893000, reward: 18.900000, loss: 0.000170, epsilon: 0.010000, episode:  417\n",
      "frames: 894000, reward: 19.100000, loss: 0.000172, epsilon: 0.010000, episode:  418\n",
      "frames: 895000, reward: 19.200000, loss: 0.000133, epsilon: 0.010000, episode:  419\n",
      "frames: 896000, reward: 19.200000, loss: 0.000157, epsilon: 0.010000, episode:  419\n",
      "frames: 897000, reward: 19.400000, loss: 0.000155, epsilon: 0.010000, episode:  420\n",
      "frames: 898000, reward: 19.400000, loss: 0.000267, epsilon: 0.010000, episode:  420\n",
      "frames: 899000, reward: 19.400000, loss: 0.000074, epsilon: 0.010000, episode:  421\n",
      "frames: 900000, reward: 19.400000, loss: 0.000134, epsilon: 0.010000, episode:  421\n",
      "frames: 901000, reward: 20.000000, loss: 0.000113, epsilon: 0.010000, episode:  422\n",
      "frames: 902000, reward: 20.300000, loss: 0.000236, epsilon: 0.010000, episode:  423\n",
      "frames: 903000, reward: 20.300000, loss: 0.000093, epsilon: 0.010000, episode:  423\n",
      "frames: 904000, reward: 20.100000, loss: 0.000290, epsilon: 0.010000, episode:  424\n",
      "frames: 905000, reward: 20.100000, loss: 0.000100, epsilon: 0.010000, episode:  424\n",
      "frames: 906000, reward: 20.000000, loss: 0.000108, epsilon: 0.010000, episode:  425\n",
      "frames: 907000, reward: 20.000000, loss: 0.000093, epsilon: 0.010000, episode:  425\n",
      "frames: 908000, reward: 19.900000, loss: 0.000288, epsilon: 0.010000, episode:  426\n",
      "frames: 909000, reward: 19.900000, loss: 0.000151, epsilon: 0.010000, episode:  426\n",
      "frames: 910000, reward: 19.900000, loss: 0.000548, epsilon: 0.010000, episode:  427\n",
      "frames: 911000, reward: 19.900000, loss: 0.000100, epsilon: 0.010000, episode:  427\n",
      "frames: 912000, reward: 19.800000, loss: 0.000251, epsilon: 0.010000, episode:  428\n",
      "frames: 913000, reward: 19.800000, loss: 0.000108, epsilon: 0.010000, episode:  429\n",
      "frames: 914000, reward: 19.800000, loss: 0.000112, epsilon: 0.010000, episode:  429\n",
      "frames: 915000, reward: 19.800000, loss: 0.000232, epsilon: 0.010000, episode:  430\n",
      "frames: 916000, reward: 19.800000, loss: 0.000161, epsilon: 0.010000, episode:  430\n",
      "frames: 917000, reward: 19.900000, loss: 0.000102, epsilon: 0.010000, episode:  431\n",
      "frames: 918000, reward: 19.900000, loss: 0.000134, epsilon: 0.010000, episode:  431\n",
      "frames: 919000, reward: 19.800000, loss: 0.000401, epsilon: 0.010000, episode:  432\n",
      "frames: 920000, reward: 19.700000, loss: 0.000224, epsilon: 0.010000, episode:  433\n",
      "frames: 921000, reward: 19.700000, loss: 0.000308, epsilon: 0.010000, episode:  433\n",
      "frames: 922000, reward: 19.700000, loss: 0.000262, epsilon: 0.010000, episode:  434\n",
      "frames: 923000, reward: 19.700000, loss: 0.001456, epsilon: 0.010000, episode:  434\n",
      "frames: 924000, reward: 19.400000, loss: 0.000126, epsilon: 0.010000, episode:  435\n",
      "frames: 925000, reward: 19.400000, loss: 0.000143, epsilon: 0.010000, episode:  435\n",
      "frames: 926000, reward: 19.600000, loss: 0.000329, epsilon: 0.010000, episode:  436\n",
      "frames: 927000, reward: 19.600000, loss: 0.000179, epsilon: 0.010000, episode:  436\n",
      "frames: 928000, reward: 19.500000, loss: 0.000118, epsilon: 0.010000, episode:  437\n",
      "frames: 929000, reward: 19.600000, loss: 0.000090, epsilon: 0.010000, episode:  438\n",
      "frames: 930000, reward: 19.600000, loss: 0.000057, epsilon: 0.010000, episode:  438\n",
      "frames: 931000, reward: 19.600000, loss: 0.000122, epsilon: 0.010000, episode:  439\n",
      "frames: 932000, reward: 19.600000, loss: 0.000150, epsilon: 0.010000, episode:  439\n",
      "frames: 933000, reward: 19.400000, loss: 0.000063, epsilon: 0.010000, episode:  440\n",
      "frames: 934000, reward: 19.400000, loss: 0.000486, epsilon: 0.010000, episode:  440\n",
      "frames: 935000, reward: 19.300000, loss: 0.000101, epsilon: 0.010000, episode:  441\n",
      "frames: 936000, reward: 19.500000, loss: 0.000097, epsilon: 0.010000, episode:  442\n",
      "frames: 937000, reward: 19.500000, loss: 0.000102, epsilon: 0.010000, episode:  442\n",
      "frames: 938000, reward: 19.400000, loss: 0.000116, epsilon: 0.010000, episode:  443\n",
      "frames: 939000, reward: 19.400000, loss: 0.000083, epsilon: 0.010000, episode:  443\n",
      "frames: 940000, reward: 19.600000, loss: 0.000105, epsilon: 0.010000, episode:  444\n",
      "frames: 941000, reward: 19.600000, loss: 0.000111, epsilon: 0.010000, episode:  444\n",
      "frames: 942000, reward: 20.000000, loss: 0.000105, epsilon: 0.010000, episode:  445\n",
      "frames: 943000, reward: 19.900000, loss: 0.000834, epsilon: 0.010000, episode:  446\n",
      "frames: 944000, reward: 19.900000, loss: 0.000103, epsilon: 0.010000, episode:  446\n",
      "frames: 945000, reward: 19.900000, loss: 0.000302, epsilon: 0.010000, episode:  447\n",
      "frames: 946000, reward: 19.900000, loss: 0.000423, epsilon: 0.010000, episode:  447\n",
      "frames: 947000, reward: 19.700000, loss: 0.000193, epsilon: 0.010000, episode:  448\n",
      "frames: 948000, reward: 19.700000, loss: 0.000112, epsilon: 0.010000, episode:  448\n",
      "frames: 949000, reward: 19.600000, loss: 0.000109, epsilon: 0.010000, episode:  449\n",
      "frames: 950000, reward: 19.600000, loss: 0.000136, epsilon: 0.010000, episode:  449\n",
      "frames: 951000, reward: 19.600000, loss: 0.000102, epsilon: 0.010000, episode:  450\n",
      "frames: 952000, reward: 19.600000, loss: 0.000083, epsilon: 0.010000, episode:  450\n",
      "frames: 953000, reward: 19.600000, loss: 0.000157, epsilon: 0.010000, episode:  451\n",
      "frames: 954000, reward: 19.600000, loss: 0.000287, epsilon: 0.010000, episode:  451\n",
      "frames: 955000, reward: 19.400000, loss: 0.000132, epsilon: 0.010000, episode:  452\n",
      "frames: 956000, reward: 19.400000, loss: 0.000187, epsilon: 0.010000, episode:  452\n",
      "frames: 957000, reward: 19.700000, loss: 0.000147, epsilon: 0.010000, episode:  453\n",
      "frames: 958000, reward: 19.600000, loss: 0.000221, epsilon: 0.010000, episode:  454\n",
      "frames: 959000, reward: 19.600000, loss: 0.000147, epsilon: 0.010000, episode:  454\n",
      "frames: 960000, reward: 19.600000, loss: 0.000180, epsilon: 0.010000, episode:  455\n",
      "frames: 961000, reward: 19.600000, loss: 0.000217, epsilon: 0.010000, episode:  455\n",
      "frames: 962000, reward: 19.700000, loss: 0.000446, epsilon: 0.010000, episode:  456\n",
      "frames: 963000, reward: 19.700000, loss: 0.000126, epsilon: 0.010000, episode:  456\n",
      "frames: 964000, reward: 19.600000, loss: 0.000371, epsilon: 0.010000, episode:  457\n",
      "frames: 965000, reward: 19.800000, loss: 0.000129, epsilon: 0.010000, episode:  458\n",
      "frames: 966000, reward: 19.800000, loss: 0.000075, epsilon: 0.010000, episode:  458\n",
      "frames: 967000, reward: 19.900000, loss: 0.000049, epsilon: 0.010000, episode:  459\n",
      "frames: 968000, reward: 19.900000, loss: 0.000097, epsilon: 0.010000, episode:  459\n",
      "frames: 969000, reward: 20.200000, loss: 0.000116, epsilon: 0.010000, episode:  460\n",
      "frames: 970000, reward: 20.200000, loss: 0.000069, epsilon: 0.010000, episode:  460\n",
      "frames: 971000, reward: 19.900000, loss: 0.000160, epsilon: 0.010000, episode:  461\n",
      "frames: 972000, reward: 20.100000, loss: 0.000158, epsilon: 0.010000, episode:  462\n",
      "frames: 973000, reward: 20.100000, loss: 0.000191, epsilon: 0.010000, episode:  462\n",
      "frames: 974000, reward: 19.900000, loss: 0.000079, epsilon: 0.010000, episode:  463\n",
      "frames: 975000, reward: 19.900000, loss: 0.000256, epsilon: 0.010000, episode:  463\n",
      "frames: 976000, reward: 19.800000, loss: 0.007116, epsilon: 0.010000, episode:  464\n",
      "frames: 977000, reward: 19.800000, loss: 0.000278, epsilon: 0.010000, episode:  464\n",
      "frames: 978000, reward: 19.600000, loss: 0.000240, epsilon: 0.010000, episode:  465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 979000, reward: 19.600000, loss: 0.000114, epsilon: 0.010000, episode:  466\n",
      "frames: 980000, reward: 19.600000, loss: 0.000141, epsilon: 0.010000, episode:  466\n",
      "frames: 981000, reward: 19.900000, loss: 0.000133, epsilon: 0.010000, episode:  467\n",
      "frames: 982000, reward: 19.900000, loss: 0.000139, epsilon: 0.010000, episode:  467\n",
      "frames: 983000, reward: 19.900000, loss: 0.000161, epsilon: 0.010000, episode:  468\n",
      "frames: 984000, reward: 19.900000, loss: 0.000083, epsilon: 0.010000, episode:  468\n",
      "frames: 985000, reward: 19.800000, loss: 0.000287, epsilon: 0.010000, episode:  469\n",
      "frames: 986000, reward: 19.800000, loss: 0.000145, epsilon: 0.010000, episode:  470\n",
      "frames: 987000, reward: 19.800000, loss: 0.000080, epsilon: 0.010000, episode:  470\n",
      "frames: 988000, reward: 20.200000, loss: 0.000254, epsilon: 0.010000, episode:  471\n",
      "frames: 989000, reward: 20.200000, loss: 0.000141, epsilon: 0.010000, episode:  471\n",
      "frames: 990000, reward: 20.100000, loss: 0.000057, epsilon: 0.010000, episode:  472\n",
      "frames: 991000, reward: 20.300000, loss: 0.000100, epsilon: 0.010000, episode:  473\n",
      "frames: 992000, reward: 20.300000, loss: 0.000282, epsilon: 0.010000, episode:  473\n",
      "frames: 993000, reward: 20.300000, loss: 0.001538, epsilon: 0.010000, episode:  474\n",
      "frames: 994000, reward: 20.300000, loss: 0.000121, epsilon: 0.010000, episode:  474\n",
      "frames: 995000, reward: 20.500000, loss: 0.000113, epsilon: 0.010000, episode:  475\n",
      "frames: 996000, reward: 20.500000, loss: 0.000116, epsilon: 0.010000, episode:  475\n",
      "frames: 997000, reward: 20.500000, loss: 0.000078, epsilon: 0.010000, episode:  476\n",
      "frames: 998000, reward: 20.600000, loss: 0.000059, epsilon: 0.010000, episode:  477\n",
      "frames: 999000, reward: 20.600000, loss: 0.000062, epsilon: 0.010000, episode:  477\n",
      "frames: 1000000, reward: 20.500000, loss: 0.000180, epsilon: 0.010000, episode:  478\n",
      "frames: 1001000, reward: 20.500000, loss: 0.000082, epsilon: 0.010000, episode:  478\n",
      "frames: 1002000, reward: 20.600000, loss: 0.000132, epsilon: 0.010000, episode:  479\n",
      "frames: 1003000, reward: 20.400000, loss: 0.000753, epsilon: 0.010000, episode:  480\n",
      "frames: 1004000, reward: 20.400000, loss: 0.000177, epsilon: 0.010000, episode:  480\n",
      "frames: 1005000, reward: 20.400000, loss: 0.006412, epsilon: 0.010000, episode:  481\n",
      "frames: 1006000, reward: 20.400000, loss: 0.000116, epsilon: 0.010000, episode:  481\n",
      "frames: 1007000, reward: 20.300000, loss: 0.000156, epsilon: 0.010000, episode:  482\n",
      "frames: 1008000, reward: 20.300000, loss: 0.000051, epsilon: 0.010000, episode:  482\n",
      "frames: 1009000, reward: 20.300000, loss: 0.000098, epsilon: 0.010000, episode:  483\n",
      "frames: 1010000, reward: 20.500000, loss: 0.000221, epsilon: 0.010000, episode:  484\n",
      "frames: 1011000, reward: 20.500000, loss: 0.000317, epsilon: 0.010000, episode:  484\n",
      "frames: 1012000, reward: 20.500000, loss: 0.000137, epsilon: 0.010000, episode:  485\n",
      "frames: 1013000, reward: 20.500000, loss: 0.000293, epsilon: 0.010000, episode:  485\n",
      "frames: 1014000, reward: 20.300000, loss: 0.000207, epsilon: 0.010000, episode:  486\n",
      "frames: 1015000, reward: 20.100000, loss: 0.000113, epsilon: 0.010000, episode:  487\n",
      "frames: 1016000, reward: 20.100000, loss: 0.000590, epsilon: 0.010000, episode:  487\n",
      "frames: 1017000, reward: 20.100000, loss: 0.000049, epsilon: 0.010000, episode:  488\n",
      "frames: 1018000, reward: 20.100000, loss: 0.000069, epsilon: 0.010000, episode:  488\n",
      "frames: 1019000, reward: 20.000000, loss: 0.000254, epsilon: 0.010000, episode:  489\n",
      "frames: 1020000, reward: 20.000000, loss: 0.000197, epsilon: 0.010000, episode:  489\n",
      "frames: 1021000, reward: 20.100000, loss: 0.000152, epsilon: 0.010000, episode:  490\n",
      "frames: 1022000, reward: 20.000000, loss: 0.000137, epsilon: 0.010000, episode:  491\n",
      "frames: 1023000, reward: 20.000000, loss: 0.000167, epsilon: 0.010000, episode:  491\n",
      "frames: 1024000, reward: 19.900000, loss: 0.000135, epsilon: 0.010000, episode:  492\n",
      "frames: 1025000, reward: 19.900000, loss: 0.000153, epsilon: 0.010000, episode:  492\n",
      "frames: 1026000, reward: 19.400000, loss: 0.000149, epsilon: 0.010000, episode:  493\n",
      "frames: 1027000, reward: 19.400000, loss: 0.000146, epsilon: 0.010000, episode:  493\n",
      "frames: 1028000, reward: 19.300000, loss: 0.000315, epsilon: 0.010000, episode:  494\n",
      "frames: 1029000, reward: 19.300000, loss: 0.000068, epsilon: 0.010000, episode:  494\n",
      "frames: 1030000, reward: 19.100000, loss: 0.000064, epsilon: 0.010000, episode:  495\n",
      "frames: 1031000, reward: 19.100000, loss: 0.000538, epsilon: 0.010000, episode:  495\n",
      "frames: 1032000, reward: 19.200000, loss: 0.000535, epsilon: 0.010000, episode:  496\n",
      "frames: 1033000, reward: 19.200000, loss: 0.002181, epsilon: 0.010000, episode:  496\n",
      "frames: 1034000, reward: 19.300000, loss: 0.000264, epsilon: 0.010000, episode:  497\n",
      "frames: 1035000, reward: 19.300000, loss: 0.000147, epsilon: 0.010000, episode:  498\n",
      "frames: 1036000, reward: 19.300000, loss: 0.000120, epsilon: 0.010000, episode:  498\n",
      "frames: 1037000, reward: 19.300000, loss: 0.000126, epsilon: 0.010000, episode:  499\n",
      "frames: 1038000, reward: 19.300000, loss: 0.000127, epsilon: 0.010000, episode:  499\n",
      "frames: 1039000, reward: 19.300000, loss: 0.000059, epsilon: 0.010000, episode:  500\n",
      "frames: 1040000, reward: 19.300000, loss: 0.000190, epsilon: 0.010000, episode:  500\n",
      "frames: 1041000, reward: 19.400000, loss: 0.000138, epsilon: 0.010000, episode:  501\n",
      "frames: 1042000, reward: 19.700000, loss: 0.000118, epsilon: 0.010000, episode:  502\n",
      "frames: 1043000, reward: 19.700000, loss: 0.000107, epsilon: 0.010000, episode:  502\n",
      "frames: 1044000, reward: 19.800000, loss: 0.000140, epsilon: 0.010000, episode:  503\n",
      "frames: 1045000, reward: 19.800000, loss: 0.000192, epsilon: 0.010000, episode:  503\n",
      "frames: 1046000, reward: 19.800000, loss: 0.000308, epsilon: 0.010000, episode:  504\n",
      "frames: 1047000, reward: 19.800000, loss: 0.000055, epsilon: 0.010000, episode:  504\n",
      "frames: 1048000, reward: 19.900000, loss: 0.000114, epsilon: 0.010000, episode:  505\n",
      "frames: 1049000, reward: 19.900000, loss: 0.000202, epsilon: 0.010000, episode:  505\n",
      "frames: 1050000, reward: 19.700000, loss: 0.000142, epsilon: 0.010000, episode:  506\n",
      "frames: 1051000, reward: 19.700000, loss: 0.000330, epsilon: 0.010000, episode:  506\n",
      "frames: 1052000, reward: 19.600000, loss: 0.000198, epsilon: 0.010000, episode:  507\n",
      "frames: 1053000, reward: 19.600000, loss: 0.000167, epsilon: 0.010000, episode:  507\n",
      "frames: 1054000, reward: 19.700000, loss: 0.000090, epsilon: 0.010000, episode:  508\n",
      "frames: 1055000, reward: 19.700000, loss: 0.000263, epsilon: 0.010000, episode:  509\n",
      "frames: 1056000, reward: 19.700000, loss: 0.000101, epsilon: 0.010000, episode:  509\n",
      "frames: 1057000, reward: 19.600000, loss: 0.000123, epsilon: 0.010000, episode:  510\n",
      "frames: 1058000, reward: 19.600000, loss: 0.000083, epsilon: 0.010000, episode:  510\n",
      "frames: 1059000, reward: 19.600000, loss: 0.000079, epsilon: 0.010000, episode:  511\n",
      "frames: 1060000, reward: 19.600000, loss: 0.000158, epsilon: 0.010000, episode:  511\n",
      "frames: 1061000, reward: 19.300000, loss: 0.000213, epsilon: 0.010000, episode:  512\n",
      "frames: 1062000, reward: 19.300000, loss: 0.000085, epsilon: 0.010000, episode:  512\n",
      "frames: 1063000, reward: 19.300000, loss: 0.000545, epsilon: 0.010000, episode:  513\n",
      "frames: 1064000, reward: 19.300000, loss: 0.000195, epsilon: 0.010000, episode:  513\n",
      "frames: 1065000, reward: 19.200000, loss: 0.000296, epsilon: 0.010000, episode:  514\n",
      "frames: 1066000, reward: 19.200000, loss: 0.000242, epsilon: 0.010000, episode:  515\n",
      "frames: 1067000, reward: 19.200000, loss: 0.000177, epsilon: 0.010000, episode:  515\n",
      "frames: 1068000, reward: 19.500000, loss: 0.000321, epsilon: 0.010000, episode:  516\n",
      "frames: 1069000, reward: 19.500000, loss: 0.000319, epsilon: 0.010000, episode:  516\n",
      "frames: 1070000, reward: 19.400000, loss: 0.000092, epsilon: 0.010000, episode:  517\n",
      "frames: 1071000, reward: 19.400000, loss: 0.000180, epsilon: 0.010000, episode:  517\n",
      "frames: 1072000, reward: 19.400000, loss: 0.000389, epsilon: 0.010000, episode:  518\n",
      "frames: 1073000, reward: 19.400000, loss: 0.000176, epsilon: 0.010000, episode:  519\n",
      "frames: 1074000, reward: 19.400000, loss: 0.000109, epsilon: 0.010000, episode:  519\n",
      "frames: 1075000, reward: 19.600000, loss: 0.000084, epsilon: 0.010000, episode:  520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 1076000, reward: 19.600000, loss: 0.002684, epsilon: 0.010000, episode:  520\n",
      "frames: 1077000, reward: 19.500000, loss: 0.001835, epsilon: 0.010000, episode:  521\n",
      "frames: 1078000, reward: 19.500000, loss: 0.000265, epsilon: 0.010000, episode:  521\n",
      "frames: 1079000, reward: 19.700000, loss: 0.000097, epsilon: 0.010000, episode:  522\n",
      "frames: 1080000, reward: 19.700000, loss: 0.000060, epsilon: 0.010000, episode:  522\n",
      "frames: 1081000, reward: 20.000000, loss: 0.000090, epsilon: 0.010000, episode:  523\n",
      "frames: 1082000, reward: 20.100000, loss: 0.000090, epsilon: 0.010000, episode:  524\n",
      "frames: 1083000, reward: 20.100000, loss: 0.000118, epsilon: 0.010000, episode:  524\n",
      "frames: 1084000, reward: 20.200000, loss: 0.002037, epsilon: 0.010000, episode:  525\n",
      "frames: 1085000, reward: 20.200000, loss: 0.001469, epsilon: 0.010000, episode:  525\n",
      "frames: 1086000, reward: 19.400000, loss: 0.000062, epsilon: 0.010000, episode:  526\n",
      "frames: 1087000, reward: 19.400000, loss: 0.000108, epsilon: 0.010000, episode:  526\n",
      "frames: 1088000, reward: 19.500000, loss: 0.000070, epsilon: 0.010000, episode:  527\n",
      "frames: 1089000, reward: 19.500000, loss: 0.000114, epsilon: 0.010000, episode:  527\n",
      "frames: 1090000, reward: 19.400000, loss: 0.000105, epsilon: 0.010000, episode:  528\n",
      "frames: 1091000, reward: 19.400000, loss: 0.000136, epsilon: 0.010000, episode:  529\n",
      "frames: 1092000, reward: 19.400000, loss: 0.000074, epsilon: 0.010000, episode:  529\n",
      "frames: 1093000, reward: 19.400000, loss: 0.000789, epsilon: 0.010000, episode:  530\n",
      "frames: 1094000, reward: 19.400000, loss: 0.000308, epsilon: 0.010000, episode:  530\n",
      "frames: 1095000, reward: 19.300000, loss: 0.000080, epsilon: 0.010000, episode:  531\n",
      "frames: 1096000, reward: 19.300000, loss: 0.000105, epsilon: 0.010000, episode:  531\n",
      "frames: 1097000, reward: 19.400000, loss: 0.000120, epsilon: 0.010000, episode:  532\n",
      "frames: 1098000, reward: 19.400000, loss: 0.000148, epsilon: 0.010000, episode:  533\n",
      "frames: 1099000, reward: 19.400000, loss: 0.000259, epsilon: 0.010000, episode:  533\n",
      "frames: 1100000, reward: 19.400000, loss: 0.000091, epsilon: 0.010000, episode:  534\n",
      "frames: 1101000, reward: 19.400000, loss: 0.000048, epsilon: 0.010000, episode:  534\n",
      "frames: 1102000, reward: 19.300000, loss: 0.000070, epsilon: 0.010000, episode:  535\n",
      "frames: 1103000, reward: 19.300000, loss: 0.000090, epsilon: 0.010000, episode:  535\n",
      "frames: 1104000, reward: 20.100000, loss: 0.000279, epsilon: 0.010000, episode:  536\n",
      "frames: 1105000, reward: 20.300000, loss: 0.000195, epsilon: 0.010000, episode:  537\n",
      "frames: 1106000, reward: 20.300000, loss: 0.000107, epsilon: 0.010000, episode:  537\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a94db37aa160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlearning_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_from_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cbbfb557be7a>\u001b[0m in \u001b[0;36mlearn_from_experience\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn_from_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mtd_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_td_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cbbfb557be7a>\u001b[0m in \u001b[0;36msample_from_buffer\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mnext_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cbbfb557be7a>\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, lazyframe)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazyframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# from Lazy frame to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazyframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "    \n",
    "# Training DQN in PongNoFrameskip-v4 \n",
    "idname = 'PongNoFrameskip-v4'\n",
    "env = make_atari(idname)\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True)\n",
    "state = env.reset()\n",
    "print(state.count())\n",
    "gamma = 0.99\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.01\n",
    "eps_decay = 30000\n",
    "frames = 2000000\n",
    "USE_CUDA = True\n",
    "learning_rate = 2e-4\n",
    "max_buff = 100000\n",
    "update_tar_interval = 1000\n",
    "batch_size = 32\n",
    "print_interval = 1000\n",
    "log_interval = 1000\n",
    "learning_start = 10000\n",
    "win_reward = 18     # Pong-v4\n",
    "win_break = True\n",
    "\n",
    "action_space = env.action_space\n",
    "action_dim = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "state_channel = env.observation_space.shape[2]\n",
    "agent = DQNAgent(in_channels = state_channel, action_space= action_space, USE_CUDA = USE_CUDA, lr = learning_rate)\n",
    "\n",
    "frame = env.reset()\n",
    "\n",
    "episode_reward = 0\n",
    "all_rewards = []\n",
    "losses = []\n",
    "episode_num = 0\n",
    "is_win = False\n",
    "# tensorboard\n",
    "summary_writer = SummaryWriter(log_dir = \"DQN_stackframe\", comment= \"good_makeatari\")\n",
    "\n",
    "# e-greedy decay\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_min + (epsilon_max - epsilon_min) * math.exp(\n",
    "            -1. * frame_idx / eps_decay)\n",
    "# plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
    "\n",
    "for i in range(frames):\n",
    "    epsilon = epsilon_by_frame(i)\n",
    "    state_tensor = agent.observe(frame)\n",
    "    action = agent.act(state_tensor, epsilon)\n",
    "    \n",
    "    next_frame, reward, done, _ = env.step(action)\n",
    "    \n",
    "    episode_reward += reward\n",
    "    agent.memory_buffer.push(frame, action, reward, next_frame, done)\n",
    "    frame = next_frame\n",
    "    \n",
    "    loss = 0\n",
    "    if agent.memory_buffer.size() >= learning_start:\n",
    "        loss = agent.learn_from_experience(batch_size)\n",
    "        losses.append(loss)\n",
    "\n",
    "    if i % print_interval == 0:\n",
    "        print(\"frames: %5d, reward: %5f, loss: %4f, epsilon: %5f, episode: %4d\" % (i, np.mean(all_rewards[-10:]), loss, epsilon, episode_num))\n",
    "        summary_writer.add_scalar(\"Temporal Difference Loss\", loss, i)\n",
    "        summary_writer.add_scalar(\"Mean Reward\", np.mean(all_rewards[-10:]), i)\n",
    "        summary_writer.add_scalar(\"Epsilon\", epsilon, i)\n",
    "        \n",
    "    if i % update_tar_interval == 0:\n",
    "        agent.DQN_target.load_state_dict(agent.DQN.state_dict())\n",
    "    \n",
    "    if done:\n",
    "        \n",
    "        frame = env.reset()\n",
    "        \n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        episode_num += 1\n",
    "        avg_reward = float(np.mean(all_rewards[-100:]))\n",
    "\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training(frame_idx, rewards, losses):\n",
    "    pd.DataFrame(rewards, columns=['Reward']).to_csv(idname, index=False)\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "plot_training(i, all_rewards, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
